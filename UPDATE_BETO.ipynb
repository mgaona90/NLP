{"cells":[{"cell_type":"markdown","source":["# MLM Training\n\nIn this notebook we'll cover the training process for masked-language modeling (MLM). First we import and initialize everything required."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dbfeb47-3270-43f4-ab9e-d2544f08a0ed"}}},{"cell_type":"code","source":["# PARTICIONO EL TEXTO X PUNTOS Y QTY DE PALABRAS\n# APLICO MISMO POST-PROCESING HECHO PARA EL CORPUS DE BETO\n# POST-PROCESING PROPIO DEL CORPUS PROPIO (EJEMPLO, PARA CHAT SOLO DEJAR LO QUE SIGUE A \"CLIENTE:\")\n# APICAR AUTOCORRECTOR\n#IDENTIFICAR SI HAY NUEVOS TOKENS (NO HAY TANTOS LA VERDAD, PORQUE SON SEGMENTOS DE PALABRAS, NO PALABRAS)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f216cc47-685d-431d-b48b-f24c6fa6078e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%pip install transformers==4.4\n%pip install torch==1.9.0\n%pip install spacy==3.1.3"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11e5dff2-3af1-45ef-aef5-773d805104c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nRequirement already satisfied: transformers==4.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (4.4.0)\nRequirement already satisfied: sacremoses in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (0.0.53)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (4.64.0)\nRequirement already satisfied: numpy&gt;=1.17 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (1.19.2)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (2022.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.4) (3.0.12)\nRequirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (0.10.3)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (2.25.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (20.9)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;transformers==4.4) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (2.10)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (1.15.0)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (1.0.1)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (8.1.3)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: torch==1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (1.9.0)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from torch==1.9.0) (4.2.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: spacy==3.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (3.1.3)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (1.0.7)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (1.8.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.1.3) (52.0.0)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (4.64.0)\nRequirement already satisfied: typer&lt;0.5.0,&gt;=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.4.1)\nRequirement already satisfied: pathy&gt;=0.3.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.6.1)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.25.1)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (3.0.6)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.4.3)\nRequirement already satisfied: wasabi&lt;1.1.0,&gt;=0.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.9.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.11.3)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.0.6)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (1.19.2)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (3.0.9)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (20.9)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.0.7)\nRequirement already satisfied: thinc&lt;8.1.0,&gt;=8.0.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (8.0.17)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.7.7)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;spacy==3.1.3) (2.4.7)\nRequirement already satisfied: smart-open&lt;6.0.0,&gt;=5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from pathy&gt;=0.3.5-&gt;spacy==3.1.3) (5.2.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4-&gt;spacy==3.1.3) (4.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2.10)\nRequirement already satisfied: click&lt;9.0.0,&gt;=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from typer&lt;0.5.0,&gt;=0.3.0-&gt;spacy==3.1.3) (8.1.3)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;spacy==3.1.3) (1.1.1)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nRequirement already satisfied: transformers==4.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (4.4.0)\nRequirement already satisfied: sacremoses in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (0.0.53)\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (4.64.0)\nRequirement already satisfied: numpy&gt;=1.17 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (1.19.2)\nRequirement already satisfied: regex!=2019.12.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (2022.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.4) (3.0.12)\nRequirement already satisfied: tokenizers&lt;0.11,&gt;=0.10.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from transformers==4.4) (0.10.3)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (2.25.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from transformers==4.4) (20.9)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;transformers==4.4) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.4) (2.10)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (1.15.0)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (1.0.1)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.4) (8.1.3)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: torch==1.9.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (1.9.0)\nRequirement already satisfied: typing-extensions in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from torch==1.9.0) (4.2.0)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nRequirement already satisfied: spacy==3.1.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (3.1.3)\nRequirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (1.0.7)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (1.8.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.1.3) (52.0.0)\nRequirement already satisfied: tqdm&lt;5.0.0,&gt;=4.38.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (4.64.0)\nRequirement already satisfied: typer&lt;0.5.0,&gt;=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.4.1)\nRequirement already satisfied: pathy&gt;=0.3.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.6.1)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.25.1)\nRequirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (3.0.6)\nRequirement already satisfied: srsly&lt;3.0.0,&gt;=2.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.4.3)\nRequirement already satisfied: wasabi&lt;1.1.0,&gt;=0.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.9.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.11.3)\nRequirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.0.6)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (1.19.2)\nRequirement already satisfied: spacy-legacy&lt;3.1.0,&gt;=3.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (3.0.9)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (20.9)\nRequirement already satisfied: catalogue&lt;2.1.0,&gt;=2.0.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (2.0.7)\nRequirement already satisfied: thinc&lt;8.1.0,&gt;=8.0.9 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (8.0.17)\nRequirement already satisfied: blis&lt;0.8.0,&gt;=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from spacy==3.1.3) (0.7.7)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;spacy==3.1.3) (2.4.7)\nRequirement already satisfied: smart-open&lt;6.0.0,&gt;=5.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from pathy&gt;=0.3.5-&gt;spacy==3.1.3) (5.2.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4-&gt;spacy==3.1.3) (4.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2.10)\nRequirement already satisfied: click&lt;9.0.0,&gt;=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/lib/python3.8/site-packages (from typer&lt;0.5.0,&gt;=0.3.0-&gt;spacy==3.1.3) (8.1.3)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;spacy==3.1.3) (1.1.1)\nWARNING: You are using pip version 21.0.1; however, version 22.1.2 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-9f469ca8-2890-4e78-80d4-138275a2b980/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# https://www.youtube.com/watch?v=R6hcxMMOrPE\n# https://towardsdatascience.com/how-to-train-bert-aaad00533168\n\nfrom transformers import BertTokenizer, BertForMaskedLM\nimport torch\nimport pandas as pd\nimport re\n\n# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\ntokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n# model = BertForMaskedLM.from_pretrained('bert-base-uncased')\nmodel = BertForMaskedLM.from_pretrained(\"/dbfs/Efecty_VoC/BETOmodel/BETO/\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94504dfd-c124-4bc4-8a1a-aa8018376d48"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Some weights of the model checkpoint at /dbfs/Efecty_VoC/BETOmodel/BETO/ were not used when initializing BertForMaskedLM: [&#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;]\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Some weights of the model checkpoint at /dbfs/Efecty_VoC/BETOmodel/BETO/ were not used when initializing BertForMaskedLM: [&#39;cls.seq_relationship.weight&#39;, &#39;cls.seq_relationship.bias&#39;]\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We'll be using *Meditations* by *Marcus Aurelius* as our training data. The file below has already been cleaned and so no further processing is required (beyond the `split`)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e5e5e4b-a2c7-4178-b685-34abdf00bef2"}}},{"cell_type":"code","source":["pd.set_option('display.max_colwidth',-1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a1da4f3b-5f27-46ad-aadf-29488f11e660"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;command-1401231740186972&gt;:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n  pd.set_option(&#39;display.max_colwidth&#39;,-1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;command-1401231740186972&gt;:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n  pd.set_option(&#39;display.max_colwidth&#39;,-1)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["import unicodedata\nimport sys\n\ndef _is_punctuation(char):\n  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n  cp = ord(char)\n  # We treat all non-letter/number ASCII as punctuation.\n  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n  # Punctuation class but we treat them as punctuation anyways, for\n  # consistency.\n  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n    return True\n  cat = unicodedata.category(char)\n  if cat.startswith(\"P\"):\n    return True\n  return False\n\ndef _run_split_on_punc(text):\n    \"\"\"Splits punctuation on a piece of text.\"\"\"\n    chars = list(text)\n    i = 0\n    start_new_word = True\n    output = []\n    while i < len(chars):\n      char = chars[i]\n      if _is_punctuation(char):\n        output.append([char])\n        start_new_word = True\n      else:\n        if start_new_word:\n          output.append([])\n        start_new_word = False\n        output[-1].append(char)\n      i += 1\n\n    return ' '.join([\"\".join(x) for x in output])\n\n#Eliminar multiespacios en blanco\ndef replace_multi_whitespaces(line):\n\treturn ' '.join(line.split())\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49fe421d-f1f9-41fd-9b9d-8d4b98678552"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df = pd.read_csv(f\"/dbfs/Efecty_VoC/BETOmodel/Datasets/Tema - Colab Encuesta.csv\", sep=',')\ndf.columns=['text','otra']\n\ndf['text']=df['text'].apply(lambda x: x.lower())\n\nfor t in range(0,len(df['text'])):\n     df['text'][t]=replace_multi_whitespaces(_run_split_on_punc(df['text'][t]))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da288b95-8a50-40d5-bd51-4c8400ebe6b7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["####POST PROCESING DEL CORPUS QUE HACEN EN BETO\n\n# corpus_processing.py\n# import re\n# import sys\n\n\n#URLS_RE = re.compile(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b')\n# URLS_RE = re.compile(r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*')\n\n# LISTING_RE = re.compile(r'^(|[a-z]?|[0-9]{0,3})(\\-|\\.)+( |\\n)')\n\n# def remove_urls(text):\n# \treturn URLS_RE.sub('', text)\n\n# def replace_multi_whitespaces(line):\n# \treturn ' '.join(line.split())\n\n# def remove_listing(line):\n# \treturn LISTING_RE.sub('', line)\n\n# def main():\t\n\n# \twith open(sys.argv[1], \"r\") as input_file:\n\n# \t\tfor line in input_file:\n# \t\t\tif line is '\\n':\n# \t\t\t\tprint('')\n# \t\t\telse:\n# \t\t\t\tline = line.lower()\n# \t\t\t\tline = remove_urls(line)\n# \t\t\t\tline = remove_listing(line)\n# \t\t\t\tline = replace_multi_whitespaces(line)\n\n# \t\t\t\tif line is not '':\n# \t\t\t\t\tprint(line)\n\n\n\n# if __name__ == '__main__':\n#     main()\n    \n    \n   "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2e09e2e-15e2-4d27-9340-3a16cdf6560b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Tratamiento de datos\nindex_ini=list(df.index)\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(r'[\\n]{1,4}',' ',x)) #Mas que nada para las PQRS que tienen muchas lineas vacias, donde hay mucho \\n textual\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(r\"\"\"[' ']{1,4}\"\"\",' ',x)) \n\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.findall(\".liente:(.*)\\**\",x) if 'liente:' in x else x)\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(r'\\?','zzz',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(r'\\.','bbb',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(',','qwqz',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub('[\\W]',' ',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub('qwqz',',',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub('bbb','.',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub('zzz','?',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub(r'\\s\\s',' ',str(x)))\ndf.loc[index_ini,'text']=df['text'].apply(lambda x: re.sub('Imagen .*? [0-9-a-z]{10,30}','',str(x)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d9530295-9447-492b-bdde-9c148e97af98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#TRABAJAR SOBRE EL CORRECTOR \n\n# from spellchecker import SpellChecker\n# spanish = SpellChecker(language='es') \n\n# text_df=pd.DataFrame(text)\n# text_df[0]=text_df[0].apply(lambda x: x.lower())\n# text_df[1]='0'\n\n# for i in range(0,len(text_df[0])):\n#     s_split= text_df[0][i].split(' ')\n#     prueba=spanish.unknown(s_split)\n#     for word in prueba:\n#       text_df[1][i]=spanish.correction(word)\n\n# text_df[0]=text_df[0].apply(lambda x: x.lower())\n\n# pd.set_option('display.max_colwidth', -1)\n# text_df[text_df[1]!='0']"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"450c01ec-32df-4532-bc18-050349b19ef1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#UPDATE TOKENS \n\n#Generar una lista de los tokens que bert considera unknow. Para beto es el token 3\n# add_tokens=[]\n# for j in range(0,len(text)):\n#    word_t=text[j].split(' ')\n#    for i in word_t:\n#      if tokenizer.convert_tokens_to_ids(tokenizer.tokenize(str(word_t)))==[3]:\n#        add_tokens.append(word_t)\n\n\n\nej: tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"游때\"))==[3]\n# special tokens: \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\n# luego,\n# tokenizer.add_tokens(['new', 'rdemorais', 'blabla']) #Identificar los tokens que no estan en tokenizer (token=100)\n# model.resize_token_embeddings(len(tokenizer)) # el shape de los embeddings depende de la qty de palabras, por eso hay que hacer un reshape"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90cce161-062d-423f-ab9d-9a17c3b7f54d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"[MASK]\"))\n# cls=4,sep=5,pad=1\n# mask=0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"262f6a93-a587-4a77-a59d-283d57a7e718"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: [0]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: [0]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["text=df['text'].tolist()\ntext[100:110]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c1c4edd4-58ff-4a00-981e-4e2b3154d827"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: [&#39;en los proyectos para pagos como revistas o claro o movistar deben indicar el nombre completo del titular para estar mas segura del pago . el tema de trabajar los s치bados m칤nimo 10 horas y domingos m칤nimo 5 horas , no va conmigo para mi es mucho mas importante dedicarle tiempo a mi esposo e hijas , no todo en la vida es trabajo . y por ultimo en mi punto como tema personal me parece injusto que no pueda recaudar otras facturas que porque efecty no tiene el convenio , de 5 a침os que llevo como independiente siempre me he caracterizado por la excelente atenci칩n y soluci칩n que le doy al cliente . as칤 no tenga convenio busco la manera de realizar los pagos as칤 sea que me toque ir o mandar a alguien a pagarlos en otro lado . ejemplo  electrohuila  . deben ser mas asequibles y no ser ego칤stas en pensar solo en ustedes como marca , la idea es darle soluci칩n a los clientes que se vayan satisfechos porque encuentran lo que realmente necesitan en un punto de atenci칩n . eso permite que el voz a voz se multiplique y sea m치s la gente que va a llegar no solo a pagar facturas si no tambi칠n a realizar giros y dem치s cosas . gracias  &#39;,\n &#39;en la mayoria de proyectos se pueda ver nombre del titular ejemplo pagos de cuotas banco , movil , tv para informarle al cliente el pago muchas veces envian otra persona a pagar&#39;,\n &#39;la mayor in5 es la disminuci칩n de las contraprestaciones , mientras el aumento del dinero que se maneja en el punto ha sido el doble . m치s riesgo para uno y menos beneficio&#39;,\n &#39;tener en cuenta que los puntos de atenci칩n deben de tener una distancia entre uno y otro en mi caso este punto tiene mas de 7 a침os funcionando en el mismo local y la se침ora de la esquina coloco el que ella tenia en otra direcci칩n a una cuadra de este , lo que es competencia desleal . gracias&#39;,\n &#39;es importante que los log칤sticos tengan la informaci칩n de los convenios nuevos que salen en especial los bingos , los cambios de c칩digo de las empresas y en especial se pueda tener una mejor comunicaci칩n ya sea por celular o watsapp , por que en eso estamos fallando mucho .&#39;,\n &#39;tratar de no perder algunos convenios con las empresas , ya que los clientes se sienten muy satisfechos con el servicios por que practicamente hacen todos sus pagos en un solo lugar .&#39;,\n &#39;buenas tardes que por favor no mas aperturas de efecty esto no da para tanto la situacion no es muy buena , los bancos con esas plataformas de nequi y daviplata nos llevan ventaja no cobran por los giros y eso a bajado el envio y retiro de los giros .&#39;,\n &#39;ampliar mas pap para brindar servicios a los usuarios en todo el territorio nacional .&#39;,\n &#39;si es posible , habilitar recaudos daviplata&#39;,\n &#39;hacer mas convenios con 4 banco , los cuales est치n brindados servicios que las nuevas generaciones est치n utilizando mucho&#39;]</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: [&#39;en los proyectos para pagos como revistas o claro o movistar deben indicar el nombre completo del titular para estar mas segura del pago . el tema de trabajar los s치bados m칤nimo 10 horas y domingos m칤nimo 5 horas , no va conmigo para mi es mucho mas importante dedicarle tiempo a mi esposo e hijas , no todo en la vida es trabajo . y por ultimo en mi punto como tema personal me parece injusto que no pueda recaudar otras facturas que porque efecty no tiene el convenio , de 5 a침os que llevo como independiente siempre me he caracterizado por la excelente atenci칩n y soluci칩n que le doy al cliente . as칤 no tenga convenio busco la manera de realizar los pagos as칤 sea que me toque ir o mandar a alguien a pagarlos en otro lado . ejemplo  electrohuila  . deben ser mas asequibles y no ser ego칤stas en pensar solo en ustedes como marca , la idea es darle soluci칩n a los clientes que se vayan satisfechos porque encuentran lo que realmente necesitan en un punto de atenci칩n . eso permite que el voz a voz se multiplique y sea m치s la gente que va a llegar no solo a pagar facturas si no tambi칠n a realizar giros y dem치s cosas . gracias  &#39;,\n &#39;en la mayoria de proyectos se pueda ver nombre del titular ejemplo pagos de cuotas banco , movil , tv para informarle al cliente el pago muchas veces envian otra persona a pagar&#39;,\n &#39;la mayor in5 es la disminuci칩n de las contraprestaciones , mientras el aumento del dinero que se maneja en el punto ha sido el doble . m치s riesgo para uno y menos beneficio&#39;,\n &#39;tener en cuenta que los puntos de atenci칩n deben de tener una distancia entre uno y otro en mi caso este punto tiene mas de 7 a침os funcionando en el mismo local y la se침ora de la esquina coloco el que ella tenia en otra direcci칩n a una cuadra de este , lo que es competencia desleal . gracias&#39;,\n &#39;es importante que los log칤sticos tengan la informaci칩n de los convenios nuevos que salen en especial los bingos , los cambios de c칩digo de las empresas y en especial se pueda tener una mejor comunicaci칩n ya sea por celular o watsapp , por que en eso estamos fallando mucho .&#39;,\n &#39;tratar de no perder algunos convenios con las empresas , ya que los clientes se sienten muy satisfechos con el servicios por que practicamente hacen todos sus pagos en un solo lugar .&#39;,\n &#39;buenas tardes que por favor no mas aperturas de efecty esto no da para tanto la situacion no es muy buena , los bancos con esas plataformas de nequi y daviplata nos llevan ventaja no cobran por los giros y eso a bajado el envio y retiro de los giros .&#39;,\n &#39;ampliar mas pap para brindar servicios a los usuarios en todo el territorio nacional .&#39;,\n &#39;si es posible , habilitar recaudos daviplata&#39;,\n &#39;hacer mas convenios con 4 banco , los cuales est치n brindados servicios que las nuevas generaciones est치n utilizando mucho&#39;]</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["First, we'll tokenize our text."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13729b1b-fbed-414c-b6ec-3d50ad4b8d09"}}},{"cell_type":"code","source":["inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acbbbfc1-b5f0-46f3-a544-d7d45e989ee6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Then we create our *labels* tensor by cloning the *input_ids* tensor."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a47a7f0-2588-49d0-83d9-e11e2fc67ac6"}}},{"cell_type":"code","source":["inputs['labels'] = inputs.input_ids.detach().clone()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52e31b55-a66a-4348-9e25-d7761d7506d6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["inputs.keys()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa19e648-5f59-46ff-9892-9eff7d384c86"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: dict_keys([&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;, &#39;labels&#39;])</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: dict_keys([&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;, &#39;labels&#39;])</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we mask tokens in the *input_ids* tensor, using the 15% probability we used before - and the **not** a *CLS* or *SEP* token condition. This time, because we have padding tokens we also need to exclude *PAD* tokens (*0* input ids)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9c9bd594-ad3c-44f1-8823-667691497b4a"}}},{"cell_type":"code","source":["# create random array of floats with equal dimensions to input_ids tensor\nrand = torch.rand(inputs.input_ids.shape)\n# create mask array\nmask_arr = (rand < 0.15) * (inputs.input_ids != 4) * \\\n           (inputs.input_ids != 5) * (inputs.input_ids != 1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2c2f9bdc-c4c8-4d60-bead-3a0f42eb1262"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And now we take take the indices of each `True` value, within each individual vector."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"75672130-0b1e-4d81-a79e-eef666ba27c5"}}},{"cell_type":"code","source":["selection = []\nqty_train=inputs.input_ids.shape[0]\n\nfor i in range(qty_train):\n    selection.append(\n        torch.flatten(mask_arr[i].nonzero()).tolist() #identifica el index que va a representar el 15% mask para los inputs quienes seran los outputs. 77 numeros (15% de 512)        \n    )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"309e54a8-975d-4f1b-9179-2ae32e52c7d0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Then apply these indices to each respective row in *input_ids*, assigning each of the values at these indices as *103*."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"360e350a-a5be-42e9-9867-bfde5db32f67"}}},{"cell_type":"code","source":["# Al 15% que se identifico de forma random para testear, en el input va a estar como 103 \nfor i in range(inputs.input_ids.shape[0]):\n    inputs.input_ids[i, selection[i]] = 0 #valor 0 es el mask!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6091aba7-6625-458d-941d-d407e385ec02"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# inputs.input_ids[1]\n# selection[2]\n\n\n\n##Quiero que me prediga los valores que fueron padding? creo que noo! revisar eso y ver de pasarlo a unos. trabajar con el len"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89569e88-467d-4254-b656-273e677ea6fb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["We can see the values *103* have been assigned in the same positions as we found *True* values in the `mask_arr` tensor.\n\nThe `inputs` tensors are now ready, and can we can begin setting them up to be fed into our model during training. We create a PyTorch dataset from our data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2371a2e-4840-4622-94e1-efbb5f597729"}}},{"cell_type":"code","source":["class MeditationsDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n    def __len__(self):\n        return len(self.encodings.input_ids)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7c1f1904-3bc5-4dfa-8a7f-b90171098411"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Initialize our data using the `MeditationsDataset` class."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3fb6e832-1cd9-428a-99b5-aa91faf6938a"}}},{"cell_type":"code","source":["dataset = MeditationsDataset(inputs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24707803-9242-4c69-9d3c-45675b18179d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And initialize the dataloader, which we'll be using to load our data into the model during training."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d78aa1-1a58-4928-a156-9ed9a56b3539"}}},{"cell_type":"code","source":["loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0312124-a819-42cd-ae6c-3475e765a41b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we can move onto setting up the training loop. First we setup GPU/CPU usage."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"820fb8a3-8744-4870-972a-6485ac9c97f4"}}},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# and move our model over to the selected device\nmodel.to(device)"],"metadata":{"tags":[],"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cffea521-eddf-4f7f-96b0-75d00a4cced4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[21]: BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(31002, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=31002, bias=True)\n    )\n  )\n)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(31002, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=31002, bias=True)\n    )\n  )\n)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Activate the training mode of our model, and initialize our optimizer (Adam with weighted decay - reduces chance of overfitting)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8812993f-18b8-4c01-b870-87d1c472a753"}}},{"cell_type":"code","source":["from transformers import AdamW\n\n# activate training mode\nmodel.train()\n# initialize optimizer\noptim = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d92f4d95-d8bc-4a82-ab4e-938198797049"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we can move onto the training loop, we'll train for two epochs (change `epochs` to modify this)."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32b00c6f-880f-4e4f-a955-efd1649a64d6"}}},{"cell_type":"code","source":["from tqdm import tqdm  # for our progress bar\n\nepochs = 1\n\nfor epoch in range(epochs):\n    # setup loop with TQDM and dataloader\n    loop = tqdm(loader, leave=True)\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n        # pull all tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        # process\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        labels=labels)\n        # extract loss\n        loss = outputs.loss\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optim.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7e89b8e2-fa25-482b-a30e-7ba7b0a0da69"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">\r  0%|          | 0/42 [00:00&lt;?, ?it/s]&lt;command-4107547303087250&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\rEpoch 0:   0%|          | 0/42 [00:15&lt;?, ?it/s]\rEpoch 0:   0%|          | 0/42 [00:15&lt;?, ?it/s, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:15&lt;10:47, 15.80s/it, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:29&lt;10:47, 15.80s/it, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:29&lt;10:47, 15.80s/it, loss=12]  \rEpoch 0:   5%|郊         | 2/42 [00:29&lt;09:31, 14.28s/it, loss=12]\rEpoch 0:   5%|郊         | 2/42 [00:40&lt;09:31, 14.28s/it, loss=12]\rEpoch 0:   5%|郊         | 2/42 [00:40&lt;09:31, 14.28s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:40&lt;08:33, 13.16s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:52&lt;08:33, 13.16s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:52&lt;08:33, 13.16s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [00:52&lt;07:55, 12.52s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [01:04&lt;07:55, 12.52s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [01:04&lt;07:55, 12.52s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:04&lt;07:33, 12.27s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:16&lt;07:33, 12.27s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:16&lt;07:33, 12.27s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:16&lt;07:24, 12.35s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:28&lt;07:24, 12.35s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:28&lt;07:24, 12.35s/it, loss=1.23] \rEpoch 0:  17%|郊걱둚        | 7/42 [01:28&lt;07:09, 12.26s/it, loss=1.23]\rEpoch 0:  17%|郊걱둚        | 7/42 [01:40&lt;07:09, 12.26s/it, loss=1.23]\rEpoch 0:  17%|郊걱둚        | 7/42 [01:40&lt;07:09, 12.26s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:40&lt;06:51, 12.11s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:52&lt;06:51, 12.11s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:52&lt;06:51, 12.11s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [01:52&lt;06:36, 12.00s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [02:06&lt;06:36, 12.00s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [02:06&lt;06:36, 12.00s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:06&lt;06:42, 12.57s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:23&lt;06:42, 12.57s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:23&lt;06:42, 12.57s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:23&lt;07:17, 14.11s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:40&lt;07:17, 14.11s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:40&lt;07:17, 14.11s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:40&lt;07:31, 15.04s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:56&lt;07:31, 15.04s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:56&lt;07:31, 15.04s/it, loss=0.72] \rEpoch 0:  31%|郊걱둗郊       | 13/42 [02:56&lt;07:22, 15.27s/it, loss=0.72]\rEpoch 0:  31%|郊걱둗郊       | 13/42 [03:11&lt;07:22, 15.27s/it, loss=0.72]\rEpoch 0:  31%|郊걱둗郊       | 13/42 [03:11&lt;07:22, 15.27s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:11&lt;07:00, 15.02s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:22&lt;07:00, 15.02s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:22&lt;07:00, 15.02s/it, loss=0.29] \rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:22&lt;06:18, 14.03s/it, loss=0.29]\rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:34&lt;06:18, 14.03s/it, loss=0.29]\rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:34&lt;06:18, 14.03s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:34&lt;05:42, 13.16s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:45&lt;05:42, 13.16s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:45&lt;05:42, 13.16s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:45&lt;05:17, 12.68s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:57&lt;05:17, 12.68s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:57&lt;05:17, 12.68s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [03:57&lt;04:58, 12.43s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [04:09&lt;04:58, 12.43s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [04:09&lt;04:58, 12.43s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:09&lt;04:42, 12.27s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:21&lt;04:42, 12.27s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:21&lt;04:42, 12.27s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:21&lt;04:28, 12.21s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:33&lt;04:28, 12.21s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:33&lt;04:28, 12.21s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:33&lt;04:16, 12.19s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:45&lt;04:16, 12.19s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:45&lt;04:16, 12.19s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:45&lt;04:01, 12.09s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:57&lt;04:01, 12.09s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:57&lt;04:01, 12.09s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [04:57&lt;03:47, 12.00s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [05:09&lt;03:47, 12.00s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [05:09&lt;03:47, 12.00s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:09&lt;03:35, 11.99s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:21&lt;03:35, 11.99s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:21&lt;03:35, 11.99s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:21&lt;03:25, 12.09s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:34&lt;03:25, 12.09s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:34&lt;03:25, 12.09s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:34&lt;03:15, 12.25s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:46&lt;03:15, 12.25s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:46&lt;03:15, 12.25s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:46&lt;03:02, 12.20s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:58&lt;03:02, 12.20s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:58&lt;03:02, 12.20s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [05:58&lt;02:51, 12.24s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [06:10&lt;02:51, 12.24s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [06:10&lt;02:51, 12.24s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:10&lt;02:37, 12.15s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:22&lt;02:37, 12.15s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:22&lt;02:37, 12.15s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:22&lt;02:25, 12.09s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:34&lt;02:25, 12.09s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:34&lt;02:25, 12.09s/it, loss=0.17] \rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:34&lt;02:11, 11.96s/it, loss=0.17]\rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:46&lt;02:11, 11.96s/it, loss=0.17]\rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:46&lt;02:11, 11.96s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:46&lt;02:00, 12.00s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:58&lt;02:00, 12.00s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:58&lt;02:00, 12.00s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [06:58&lt;01:48, 12.09s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [07:11&lt;01:48, 12.09s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [07:11&lt;01:48, 12.09s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:11&lt;01:37, 12.22s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:23&lt;01:37, 12.22s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:23&lt;01:37, 12.22s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:23&lt;01:25, 12.21s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:34&lt;01:25, 12.21s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:34&lt;01:25, 12.21s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:34&lt;01:11, 11.98s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:46&lt;01:11, 11.98s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:46&lt;01:11, 11.98s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:46&lt;00:59, 11.87s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:57&lt;00:59, 11.87s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:57&lt;00:59, 11.87s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [07:57&lt;00:47, 11.80s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [08:09&lt;00:47, 11.80s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [08:09&lt;00:47, 11.80s/it, loss=0.14] \rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:09&lt;00:35, 11.69s/it, loss=0.14]\rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:20&lt;00:35, 11.69s/it, loss=0.14]\rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:20&lt;00:35, 11.69s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:20&lt;00:23, 11.62s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:33&lt;00:23, 11.62s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:33&lt;00:23, 11.62s/it, loss=0.14] \rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:33&lt;00:11, 11.88s/it, loss=0.14]\rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:34&lt;00:11, 11.88s/it, loss=0.14]\rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:34&lt;00:11, 11.88s/it, loss=0.138]\rEpoch 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 42/42 [08:34&lt;00:00,  8.80s/it, loss=0.138]\rEpoch 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 42/42 [08:34&lt;00:00, 12.26s/it, loss=0.138]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r  0%|          | 0/42 [00:00&lt;?, ?it/s]&lt;command-4107547303087250&gt;:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\rEpoch 0:   0%|          | 0/42 [00:15&lt;?, ?it/s]\rEpoch 0:   0%|          | 0/42 [00:15&lt;?, ?it/s, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:15&lt;10:47, 15.80s/it, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:29&lt;10:47, 15.80s/it, loss=17.5]\rEpoch 0:   2%|郊         | 1/42 [00:29&lt;10:47, 15.80s/it, loss=12]  \rEpoch 0:   5%|郊         | 2/42 [00:29&lt;09:31, 14.28s/it, loss=12]\rEpoch 0:   5%|郊         | 2/42 [00:40&lt;09:31, 14.28s/it, loss=12]\rEpoch 0:   5%|郊         | 2/42 [00:40&lt;09:31, 14.28s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:40&lt;08:33, 13.16s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:52&lt;08:33, 13.16s/it, loss=7.52]\rEpoch 0:   7%|郊         | 3/42 [00:52&lt;08:33, 13.16s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [00:52&lt;07:55, 12.52s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [01:04&lt;07:55, 12.52s/it, loss=2.81]\rEpoch 0:  10%|郊         | 4/42 [01:04&lt;07:55, 12.52s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:04&lt;07:33, 12.27s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:16&lt;07:33, 12.27s/it, loss=0.635]\rEpoch 0:  12%|郊걱둞        | 5/42 [01:16&lt;07:33, 12.27s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:16&lt;07:24, 12.35s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:28&lt;07:24, 12.35s/it, loss=0.698]\rEpoch 0:  14%|郊걱둜        | 6/42 [01:28&lt;07:24, 12.35s/it, loss=1.23] \rEpoch 0:  17%|郊걱둚        | 7/42 [01:28&lt;07:09, 12.26s/it, loss=1.23]\rEpoch 0:  17%|郊걱둚        | 7/42 [01:40&lt;07:09, 12.26s/it, loss=1.23]\rEpoch 0:  17%|郊걱둚        | 7/42 [01:40&lt;07:09, 12.26s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:40&lt;06:51, 12.11s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:52&lt;06:51, 12.11s/it, loss=1.45]\rEpoch 0:  19%|郊걱둘        | 8/42 [01:52&lt;06:51, 12.11s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [01:52&lt;06:36, 12.00s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [02:06&lt;06:36, 12.00s/it, loss=2.23]\rEpoch 0:  21%|郊걱둗郊       | 9/42 [02:06&lt;06:36, 12.00s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:06&lt;06:42, 12.57s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:23&lt;06:42, 12.57s/it, loss=1.13]\rEpoch 0:  24%|郊걱둗郊       | 10/42 [02:23&lt;06:42, 12.57s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:23&lt;07:17, 14.11s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:40&lt;07:17, 14.11s/it, loss=0.924]\rEpoch 0:  26%|郊걱둗郊       | 11/42 [02:40&lt;07:17, 14.11s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:40&lt;07:31, 15.04s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:56&lt;07:31, 15.04s/it, loss=0.633]\rEpoch 0:  29%|郊걱둗郊       | 12/42 [02:56&lt;07:31, 15.04s/it, loss=0.72] \rEpoch 0:  31%|郊걱둗郊       | 13/42 [02:56&lt;07:22, 15.27s/it, loss=0.72]\rEpoch 0:  31%|郊걱둗郊       | 13/42 [03:11&lt;07:22, 15.27s/it, loss=0.72]\rEpoch 0:  31%|郊걱둗郊       | 13/42 [03:11&lt;07:22, 15.27s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:11&lt;07:00, 15.02s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:22&lt;07:00, 15.02s/it, loss=0.339]\rEpoch 0:  33%|郊걱둗郊걱둝      | 14/42 [03:22&lt;07:00, 15.02s/it, loss=0.29] \rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:22&lt;06:18, 14.03s/it, loss=0.29]\rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:34&lt;06:18, 14.03s/it, loss=0.29]\rEpoch 0:  36%|郊걱둗郊걱둛      | 15/42 [03:34&lt;06:18, 14.03s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:34&lt;05:42, 13.16s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:45&lt;05:42, 13.16s/it, loss=0.321]\rEpoch 0:  38%|郊걱둗郊걱둙      | 16/42 [03:45&lt;05:42, 13.16s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:45&lt;05:17, 12.68s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:57&lt;05:17, 12.68s/it, loss=0.362]\rEpoch 0:  40%|郊걱둗郊걱둗      | 17/42 [03:57&lt;05:17, 12.68s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [03:57&lt;04:58, 12.43s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [04:09&lt;04:58, 12.43s/it, loss=0.268]\rEpoch 0:  43%|郊걱둗郊걱둗郊     | 18/42 [04:09&lt;04:58, 12.43s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:09&lt;04:42, 12.27s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:21&lt;04:42, 12.27s/it, loss=0.296]\rEpoch 0:  45%|郊걱둗郊걱둗郊     | 19/42 [04:21&lt;04:42, 12.27s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:21&lt;04:28, 12.21s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:33&lt;04:28, 12.21s/it, loss=0.334]\rEpoch 0:  48%|郊걱둗郊걱둗郊     | 20/42 [04:33&lt;04:28, 12.21s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:33&lt;04:16, 12.19s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:45&lt;04:16, 12.19s/it, loss=0.288]\rEpoch 0:  50%|郊걱둗郊걱둗郊     | 21/42 [04:45&lt;04:16, 12.19s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:45&lt;04:01, 12.09s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:57&lt;04:01, 12.09s/it, loss=0.252]\rEpoch 0:  52%|郊걱둗郊걱둗郊걱둞    | 22/42 [04:57&lt;04:01, 12.09s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [04:57&lt;03:47, 12.00s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [05:09&lt;03:47, 12.00s/it, loss=0.231]\rEpoch 0:  55%|郊걱둗郊걱둗郊걱둜    | 23/42 [05:09&lt;03:47, 12.00s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:09&lt;03:35, 11.99s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:21&lt;03:35, 11.99s/it, loss=0.187]\rEpoch 0:  57%|郊걱둗郊걱둗郊걱둚    | 24/42 [05:21&lt;03:35, 11.99s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:21&lt;03:25, 12.09s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:34&lt;03:25, 12.09s/it, loss=0.151]\rEpoch 0:  60%|郊걱둗郊걱둗郊걱둘    | 25/42 [05:34&lt;03:25, 12.09s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:34&lt;03:15, 12.25s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:46&lt;03:15, 12.25s/it, loss=0.158]\rEpoch 0:  62%|郊걱둗郊걱둗郊걱둗郊   | 26/42 [05:46&lt;03:15, 12.25s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:46&lt;03:02, 12.20s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:58&lt;03:02, 12.20s/it, loss=0.159]\rEpoch 0:  64%|郊걱둗郊걱둗郊걱둗郊   | 27/42 [05:58&lt;03:02, 12.20s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [05:58&lt;02:51, 12.24s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [06:10&lt;02:51, 12.24s/it, loss=0.179]\rEpoch 0:  67%|郊걱둗郊걱둗郊걱둗郊   | 28/42 [06:10&lt;02:51, 12.24s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:10&lt;02:37, 12.15s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:22&lt;02:37, 12.15s/it, loss=0.175]\rEpoch 0:  69%|郊걱둗郊걱둗郊걱둗郊   | 29/42 [06:22&lt;02:37, 12.15s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:22&lt;02:25, 12.09s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:34&lt;02:25, 12.09s/it, loss=0.145]\rEpoch 0:  71%|郊걱둗郊걱둗郊걱둗郊걱둞  | 30/42 [06:34&lt;02:25, 12.09s/it, loss=0.17] \rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:34&lt;02:11, 11.96s/it, loss=0.17]\rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:46&lt;02:11, 11.96s/it, loss=0.17]\rEpoch 0:  74%|郊걱둗郊걱둗郊걱둗郊걱둜  | 31/42 [06:46&lt;02:11, 11.96s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:46&lt;02:00, 12.00s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:58&lt;02:00, 12.00s/it, loss=0.147]\rEpoch 0:  76%|郊걱둗郊걱둗郊걱둗郊걱둛  | 32/42 [06:58&lt;02:00, 12.00s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [06:58&lt;01:48, 12.09s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [07:11&lt;01:48, 12.09s/it, loss=0.114]\rEpoch 0:  79%|郊걱둗郊걱둗郊걱둗郊걱둙  | 33/42 [07:11&lt;01:48, 12.09s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:11&lt;01:37, 12.22s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:23&lt;01:37, 12.22s/it, loss=0.263]\rEpoch 0:  81%|郊걱둗郊걱둗郊걱둗郊걱둗  | 34/42 [07:23&lt;01:37, 12.22s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:23&lt;01:25, 12.21s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:34&lt;01:25, 12.21s/it, loss=0.209]\rEpoch 0:  83%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 35/42 [07:34&lt;01:25, 12.21s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:34&lt;01:11, 11.98s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:46&lt;01:11, 11.98s/it, loss=0.162]\rEpoch 0:  86%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 36/42 [07:46&lt;01:11, 11.98s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:46&lt;00:59, 11.87s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:57&lt;00:59, 11.87s/it, loss=0.123]\rEpoch 0:  88%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 37/42 [07:57&lt;00:59, 11.87s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [07:57&lt;00:47, 11.80s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [08:09&lt;00:47, 11.80s/it, loss=0.154]\rEpoch 0:  90%|郊걱둗郊걱둗郊걱둗郊걱둗郊 | 38/42 [08:09&lt;00:47, 11.80s/it, loss=0.14] \rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:09&lt;00:35, 11.69s/it, loss=0.14]\rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:20&lt;00:35, 11.69s/it, loss=0.14]\rEpoch 0:  93%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둝| 39/42 [08:20&lt;00:35, 11.69s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:20&lt;00:23, 11.62s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:33&lt;00:23, 11.62s/it, loss=0.125]\rEpoch 0:  95%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둛| 40/42 [08:33&lt;00:23, 11.62s/it, loss=0.14] \rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:33&lt;00:11, 11.88s/it, loss=0.14]\rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:34&lt;00:11, 11.88s/it, loss=0.14]\rEpoch 0:  98%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둙| 41/42 [08:34&lt;00:11, 11.88s/it, loss=0.138]\rEpoch 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 42/42 [08:34&lt;00:00,  8.80s/it, loss=0.138]\rEpoch 0: 100%|郊걱둗郊걱둗郊걱둗郊걱둗郊걱둗| 42/42 [08:34&lt;00:00, 12.26s/it, loss=0.138]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Save model\n# model.save_pretrained(f'/dbfs/Efecty_VoC/test/BETOV4_upd')\n# dbutils.fs.cp(f'mnt/contenedor/Efecty_VoC/NLP Models/BETO/vocab.txt',f'/dbfs/Efecty_VoC/test/BETOV4_upd/vocab.txt')\n\n\n#otra forma\n# name_file=f'/dbfs/Efecty_VoC/BETOmodel/BETO_UPDATEV1_con_textos_colab_red.pkl'\n# torch.save(model,name_file)\n# dbutils.fs.cp(f'/Efecty_VoC/BETOmodel/Modelo_Tema1_{str(dt.date.today())}.pkl',f'/mnt/contenedor/Efecty_VoC/NLP Models/Modelos/Modelo_Tema1_{str(dt.date.today())}.pkl')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ce6cb50e-9e1f-400f-a276-65b49d0bbb49"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[24]: True</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: True</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["And there we go, we've fine-tuned our BERT model using MLM on *Meditations*!"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f305deba-c00d-4606-b8c7-3ba3440f6f26"}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.8.8","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"UPDATE_BETO_efecty","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":4107547303087226}},"nbformat":4,"nbformat_minor":0}
