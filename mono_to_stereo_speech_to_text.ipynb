{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testeo mono audio.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfwH1_N7rgj_"
      },
      "outputs": [],
      "source": [
        "# for speechbrain\n",
        "!pip install -qq torch==1.11.0 torchvision==0.12.0 torchaudio==0.11.0 torchtext==0.12.0\n",
        "!pip install -qq speechbrain==0.5.12\n",
        "\n",
        "# pyannote.audio\n",
        "!pip install -qq pyannote.audio\n",
        "!pip install audio2numpy\n",
        "# for visualization purposes\n",
        "!pip install -qq moviepy ipython==7.34.0\n",
        "\n",
        "!pip install pydub\n",
        "!pip install transformers\n",
        "!pip install pyctcdecode\n",
        "!pip install pypi-kenlm\n",
        "\n",
        "# !pip install asrecognition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "audio_file = '/content/drive/My Drive/Audio - Speech/Speaker recognition/split_audio lll.wav'\n",
        "#AUDIO TIENE QUE ESTAR EN FORMATO WAV, EN 16KHZ Y EN MONO. SINO VA A ROMPER"
      ],
      "metadata": {
        "id": "JUDCyUxDrlLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PARA ESCUCHARLO\n",
        "\n",
        "# from pyannote.audio import Audio \n",
        "# from IPython.display import Audio as IPythonAudio\n",
        "# from pyannote.core import Segment, notebook\n",
        "# EXCERPT = Segment(0, 30)\n",
        "# waveform, sr = Audio().crop(audio_file, EXCERPT)"
      ],
      "metadata": {
        "id": "d1wW0XIQrnTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "pipeline = Pipeline.from_pretrained('pyannote/speaker-diarization') \n",
        "diarization = pipeline(audio_file, num_speakers=2)"
      ],
      "metadata": {
        "id": "2GPUcLWGrpqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diarization"
      ],
      "metadata": {
        "id": "RJozd1WDCokr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "#SEGMENTO SPEAKERS\n",
        "segmentos_speaker_0=[]\n",
        "segmentos_speaker_1=[]\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "  if speaker=='SPEAKER_00':\n",
        "    segmentos_speaker_0.append([turn.start*1000,turn.end*1000])\n",
        "  else:\n",
        "    segmentos_speaker_1.append([turn.start*1000,turn.end*1000])\n",
        "\n",
        "a = AudioSegment.from_wav(audio_file)\n",
        "s_inicial = AudioSegment.silent(0) #tiempo máximo del audio\n",
        "s1 = AudioSegment.silent(segmentos_speaker_0[-1][1]) #tiempo máximo del audio\n",
        "contador=0\n",
        "final_audio_speaker1=s_inicial\n",
        "aux=0\n",
        "for i,j in segmentos_speaker_0:\n",
        "  if aux!=0:\n",
        "    final_audio_speaker1=final_audio_speaker1+s1[f_anterior:i]+a[i:j]\n",
        "  else:\n",
        "    final_audio_speaker1=s1[0:i]+a[i:j]\n",
        "  f_anterior=j\n",
        "  aux=aux+1\n",
        "\n",
        "\n",
        "  # Modifico formato para correrle speech to text\n",
        "\n",
        "import numpy as np\n",
        "sample=final_audio_speaker1.get_array_of_samples()\n",
        "sample = np.array(sample)\n",
        "sample\n",
        "sample = sample.astype('float')"
      ],
      "metadata": {
        "id": "5xa070Y2C7X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_audio_speaker1"
      ],
      "metadata": {
        "id": "QNaTL9u63TIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SYfD4E_yWcvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPEECH TO TEXT"
      ],
      "metadata": {
        "id": "bJlhqlq9r-fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "from transformers import Wav2Vec2CTCTokenizer,Wav2Vec2FeatureExtractor\n",
        "\n",
        "modelo=\"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\" #\"patrickvonplaten/wav2vec2-large-xlsr-53-spanish-with-lm\" #\"jonatasgrosman/wav2vec2-large-xlsr-53-spanish\"\n",
        "model = Wav2Vec2ForCTC.from_pretrained(modelo)\n",
        "processor = Wav2Vec2Processor.from_pretrained(modelo)"
      ],
      "metadata": {
        "id": "s-Ntwv3G3OjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import audio2numpy as a2n\n",
        "# audio_file2=(a2n.audio_from_file(audio_file))"
      ],
      "metadata": {
        "id": "G59DrLYA3TcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = processor(sample, sampling_rate=16_000, return_tensors=\"pt\")\n",
        "\n",
        "import torch\n",
        "with torch.no_grad():\n",
        "  logits = model(**inputs).logits\n",
        "\n",
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = processor.batch_decode(predicted_ids)\n",
        "transcription[0].lower()"
      ],
      "metadata": {
        "id": "ovi3pDZg3Whb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}