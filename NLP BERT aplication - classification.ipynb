{"cells":[{"cell_type":"markdown","source":["# Proceso\n\n- Importar librerias\n- Carga de modelos\n- Consulta datos diarios a synapse\n- Limpieza y preprocesamiento de datos\n- Configuración BETO\n- Modelos:\n  - Indicador pregunta\n  - Sentimiento\n  - Temas\n  - Causa raiz\n  - Palabra\n  - Punto Interacción\n  - Customer journey\n- Carga de datos\n\n\n- Resultado\nCrea columnas en BT_COMENTARIOS\n  - indicador_id, sentimiento,tema_id,Causa raiz_id,(descargar modelo),palabra,punto interacción_id,customer journey_id \n\n- Crea las siguientes tablas diccionarios 1 vez\n  - LK_INDICADOR, LK_TEMA,LK_CAUSA_RAIZ,LK_PUNTO_INTERACCION,LK_CUSTOMER_JOURNEY"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4129ce57-32c2-4b86-8cc9-03057eec8e0a"}}},{"cell_type":"markdown","source":["# Ejecuciones Unicas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"24ed7160-60e4-4b8c-bbb9-590e40af6564"}}},{"cell_type":"code","source":["# Traer modelos del datalake para que los pueda llamar desde torch. esto se hace 1 sola vez!\n# crear: dbutils.fs.cp('/mnt/contenedor/Efecty_VoC/NLP Models/model_CustomerJourneyV1_BETO_uncased_fine_tune.pkl','/Efecty_VoC/BETOmodel/model_CustomerJourneyV1_BETO_uncased_fine_tune.pkl.pkl')\n\n# dbutils.fs.cp('/mnt/contenedor/Efecty_VoC/NLP Models/Modelos/BETO_sentimiento_V2.pkl','/Efecty_VoC/BETOmodel/BETO_sentimiento_V2.pkl')\n\n# CJ para cliente final e naturalV6.pkl\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73733937-c6e5-4942-90ab-47b69dd4c40c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Instalar Librerias"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7f11d22-3eed-40f8-9e8a-5cfbf3d20b3e"}}},{"cell_type":"code","source":["%pip install torch==1.9.0\n%pip install click==8.0.4\n%pip install spacy==3.1.3\n%pip install transformers==4.15.0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"344716a0-f601-49e4-8ef2-70f1a62d4578"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting torch==1.9.0\n  Using cached torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\nCollecting typing-extensions\n  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\nInstalling collected packages: typing-extensions, torch\nSuccessfully installed torch-1.9.0 typing-extensions-4.2.0\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting click==8.0.4\n  Using cached click-8.0.4-py3-none-any.whl (97 kB)\nInstalling collected packages: click\nSuccessfully installed click-8.0.4\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting spacy==3.1.3\n  Using cached spacy-3.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0\n  Using cached murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nCollecting pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4\n  Using cached pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.1.3) (52.0.0)\nCollecting tqdm&lt;5.0.0,&gt;=4.38.0\n  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\nCollecting typer&lt;0.5.0,&gt;=0.3.0\n  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\nCollecting pathy&gt;=0.3.5\n  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.25.1)\nCollecting preshed&lt;3.1.0,&gt;=3.0.2\n  Using cached preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\nCollecting srsly&lt;3.0.0,&gt;=2.4.1\n  Using cached srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\nCollecting wasabi&lt;1.1.0,&gt;=0.8.1\n  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.11.3)\nCollecting cymem&lt;2.1.0,&gt;=2.0.2\n  Using cached cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (1.19.2)\nCollecting spacy-legacy&lt;3.1.0,&gt;=3.0.8\n  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (20.9)\nCollecting catalogue&lt;2.1.0,&gt;=2.0.6\n  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\nCollecting thinc&lt;8.1.0,&gt;=8.0.9\n  Using cached thinc-8.0.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (663 kB)\nCollecting blis&lt;0.8.0,&gt;=0.4.0\n  Using cached blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;spacy==3.1.3) (2.4.7)\nCollecting smart-open&lt;6.0.0,&gt;=5.0.0\n  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4-&gt;spacy==3.1.3) (4.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2.10)\nRequirement already satisfied: click&lt;9.0.0,&gt;=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from typer&lt;0.5.0,&gt;=0.3.0-&gt;spacy==3.1.3) (8.0.4)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;spacy==3.1.3) (1.1.1)\nInstalling collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, tqdm, thinc, spacy-legacy, pathy, spacy\nSuccessfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 murmurhash-1.0.7 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.9 srsly-2.4.3 thinc-8.0.15 tqdm-4.64.0 typer-0.4.1 wasabi-0.9.1\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting transformers==4.15.0\n  Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\nCollecting sacremoses\n  Using cached sacremoses-0.0.53-py3-none-any.whl\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from transformers==4.15.0) (4.64.0)\nRequirement already satisfied: numpy&gt;=1.17 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (1.19.2)\nRequirement already satisfied: pyyaml&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (6.0)\nCollecting regex!=2019.12.17\n  Using cached regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.15.0) (3.0.12)\nCollecting tokenizers&lt;0.11,&gt;=0.10.1\n  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\nCollecting huggingface-hub&lt;1.0,&gt;=0.1.0\n  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (2.25.1)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (20.9)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers==4.15.0) (4.2.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;transformers==4.15.0) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (2.10)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (1.15.0)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (1.0.1)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (8.0.4)\nInstalling collected packages: regex, tokenizers, sacremoses, huggingface-hub, transformers\nSuccessfully installed huggingface-hub-0.5.1 regex-2022.4.24 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.15.0\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting torch==1.9.0\n  Using cached torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\nCollecting typing-extensions\n  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\nInstalling collected packages: typing-extensions, torch\nSuccessfully installed torch-1.9.0 typing-extensions-4.2.0\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting click==8.0.4\n  Using cached click-8.0.4-py3-none-any.whl (97 kB)\nInstalling collected packages: click\nSuccessfully installed click-8.0.4\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting spacy==3.1.3\n  Using cached spacy-3.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.1 MB)\nCollecting murmurhash&lt;1.1.0,&gt;=0.28.0\n  Using cached murmurhash-1.0.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\nCollecting pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4\n  Using cached pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.1.3) (52.0.0)\nCollecting tqdm&lt;5.0.0,&gt;=4.38.0\n  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\nCollecting typer&lt;0.5.0,&gt;=0.3.0\n  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\nCollecting pathy&gt;=0.3.5\n  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\nRequirement already satisfied: requests&lt;3.0.0,&gt;=2.13.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.25.1)\nCollecting preshed&lt;3.1.0,&gt;=3.0.2\n  Using cached preshed-3.0.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\nCollecting srsly&lt;3.0.0,&gt;=2.4.1\n  Using cached srsly-2.4.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\nCollecting wasabi&lt;1.1.0,&gt;=0.8.1\n  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (2.11.3)\nCollecting cymem&lt;2.1.0,&gt;=2.0.2\n  Using cached cymem-2.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\nRequirement already satisfied: numpy&gt;=1.15.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (1.19.2)\nCollecting spacy-legacy&lt;3.1.0,&gt;=3.0.8\n  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from spacy==3.1.3) (20.9)\nCollecting catalogue&lt;2.1.0,&gt;=2.0.6\n  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\nCollecting thinc&lt;8.1.0,&gt;=8.0.9\n  Using cached thinc-8.0.15-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (663 kB)\nCollecting blis&lt;0.8.0,&gt;=0.4.0\n  Using cached blis-0.7.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;spacy==3.1.3) (2.4.7)\nCollecting smart-open&lt;6.0.0,&gt;=5.0.0\n  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,&lt;1.9.0,&gt;=1.7.4-&gt;spacy==3.1.3) (4.2.0)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3.0.0,&gt;=2.13.0-&gt;spacy==3.1.3) (2.10)\nRequirement already satisfied: click&lt;9.0.0,&gt;=7.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from typer&lt;0.5.0,&gt;=0.3.0-&gt;spacy==3.1.3) (8.0.4)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /databricks/python3/lib/python3.8/site-packages (from jinja2-&gt;spacy==3.1.3) (1.1.1)\nInstalling collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, tqdm, thinc, spacy-legacy, pathy, spacy\nSuccessfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 murmurhash-1.0.7 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.1.3 spacy-legacy-3.0.9 srsly-2.4.3 thinc-8.0.15 tqdm-4.64.0 typer-0.4.1 wasabi-0.9.1\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nCollecting transformers==4.15.0\n  Using cached transformers-4.15.0-py3-none-any.whl (3.4 MB)\nCollecting sacremoses\n  Using cached sacremoses-0.0.53-py3-none-any.whl\nRequirement already satisfied: tqdm&gt;=4.27 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from transformers==4.15.0) (4.64.0)\nRequirement already satisfied: numpy&gt;=1.17 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (1.19.2)\nRequirement already satisfied: pyyaml&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (6.0)\nCollecting regex!=2019.12.17\n  Using cached regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.15.0) (3.0.12)\nCollecting tokenizers&lt;0.11,&gt;=0.10.1\n  Using cached tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\nCollecting huggingface-hub&lt;1.0,&gt;=0.1.0\n  Using cached huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (2.25.1)\nRequirement already satisfied: packaging&gt;=20.0 in /databricks/python3/lib/python3.8/site-packages (from transformers==4.15.0) (20.9)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from huggingface-hub&lt;1.0,&gt;=0.1.0-&gt;transformers==4.15.0) (4.2.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging&gt;=20.0-&gt;transformers==4.15.0) (2.4.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests-&gt;transformers==4.15.0) (2.10)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (1.15.0)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (1.0.1)\nRequirement already satisfied: click in /local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/lib/python3.8/site-packages (from sacremoses-&gt;transformers==4.15.0) (8.0.4)\nInstalling collected packages: regex, tokenizers, sacremoses, huggingface-hub, transformers\nSuccessfully installed huggingface-hub-0.5.1 regex-2022.4.24 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.15.0\nWARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-7048512e-39a5-4793-93e6-c46050d7977f/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Importar Librerias"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1942eeb-8f03-479c-a4e2-ebaf7634719b"}}},{"cell_type":"code","source":["import yaml #6.0'\nimport pandas as pd #1.2.4\nimport numpy as np #1.19.2\nimport torch #1.9.0\nimport json #2.0.9\nimport os\nimport re #'2.2.1\nimport spacy #3.1.3\nimport requests #2.25.1 \nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom pytz import timezone\nfrom torch import nn #1.9.0+cpu \nfrom transformers import AutoTokenizer,AutoModelForCausalLM #4.15.0 \nfrom transformers import BertModel,BertTokenizer #4.15.0 \nfrom sklearn.model_selection import train_test_split #0.24.1 \nfrom datetime import datetime, timedelta \n\nos.system('python -m spacy download es_core_news_lg')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdaef4f1-b051-4bb2-9a23-a27304ede536"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[1]: 0</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: 0</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Param / Config"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f1345dde-06a1-48a9-85fc-38aab1a3595e"}}},{"cell_type":"code","source":["# DEFINICION DE TIMEZONE\nTIMEZONE_COLOMBIA = 'America/Bogota'\n\n# PATH GENERACION LKs EN DATALAKE\npath_contenedor_lk = '/mnt/contenedor/Efecty_VoC/NLP Models/Tablas LK'\npath_contenedor_bt = '/mnt/contenedor/Efecty_VoC/NLP Models/NLP Diario'\n\n# PARAMETROS DE LLAMADA\ndbutils.widgets.text(\"param_FechaDesde\", \"\", \"Fecha Desde\")\ndbutils.widgets.text(\"param_FechaHasta\", \"\", \"Fecha Hasta\")\n\n# LEO ARCHICO YAML PARA RECUPERAR PARAMETROS DE CONEXION\ndbutils.fs.cp('/mnt/contenedor/Efecty_VoC/config_yaml/secrets.yml', '/Efecty_VoC/config_yaml/secrets.yml')\nsecret_file = \"/dbfs/Efecty_VoC/config_yaml/secrets.yml\"\n\nwith open(secret_file, 'r') as f:\n    try:\n        yaml_args = yaml.safe_load(f)\n        \n        #Synapse\n        synapse_url = yaml_args['connection']['sql_synapse']['url']\n        synapse_user = yaml_args['connection']['sql_synapse']['user']\n        synapse_password = yaml_args['connection']['sql_synapse']['password']\n        synapse_host = yaml_args['connection']['sql_synapse']['host']\n        synapse_database = yaml_args['connection']['sql_synapse']['databaseName']\n                    \n    except yaml.YAMLError:\n        print('Error al parsear el yaml')\n        raise\n\n\nvar_FechaDesde = dbutils.widgets.get(\"param_FechaDesde\")\nvar_FechaHasta = dbutils.widgets.get(\"param_FechaHasta\")\n\nif not(var_FechaHasta): \n    var_FechaHasta_Query = datetime.now().astimezone(timezone(TIMEZONE_COLOMBIA)).strftime('%Y-%m-%d')\n    var_FechaHasta = (datetime.now().astimezone(timezone(TIMEZONE_COLOMBIA)) + timedelta(days = -1)).strftime('%Y-%m-%d')\nelse:\n    var_FechaHasta_Query = (datetime.strptime(var_FechaHasta, '%Y-%m-%d') + timedelta(days = 1)).strftime('%Y-%m-%d')\n\n    \nif not(var_FechaDesde): var_FechaDesde = (datetime.now().astimezone(timezone(TIMEZONE_COLOMBIA)) + timedelta(days = -1)).strftime('%Y-%m-%d')\n\nprint(f'Fecha Desde: {var_FechaDesde}')\nprint(f'Fecha Hasta: {var_FechaHasta}')\nprint(f'Fecha Hasta Query: {var_FechaHasta_Query}')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"612c729b-0f14-4928-94d1-3d229a291d48"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Fecha Desde: 2022-05-02\nFecha Hasta: 2022-05-02\nFecha Hasta Query: 2022-05-03\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Fecha Desde: 2022-05-02\nFecha Hasta: 2022-05-02\nFecha Hasta Query: 2022-05-03\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Dataset Query"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f39b5ef-179a-4e96-a0dd-080577d8d3d7"}}},{"cell_type":"code","source":["# PI.INDICADOR, \n# JOIN EFECTY_VOC.BT_INTERACCIONES I ON C.INTERACCION_ID = I.INTERACCION_ID \n# LEFT JOIN EFECTY_VOC.LK_PREG_INDIC PI ON PI.PREGUNTA_ID = C.PREGUNTA_ID\n\nquery = f\"\"\"\n        SELECT\n        C.ID, C.INTERACCION_ID, C.PREGUNTA_ID, C.TEMA_ID, C.COMENTARIO, C.WRAPUPNOTE, C.WRAPUP_ID, C.VALOR, C.SUBTIPO as SUBTIPO_BT, C.SENTIMIENTO, C.FECHA_PROCESO, C.CLASE_ID, \n        P.PREGUNTA, P.ENCUESTA, I.FECHA, I.NRO_CASO_PQRS, I.DATO_ID, I.MEDIO_INGRESO_ID, M.CANAL, M.MEDIO_INGRESO, W.WRAPUP, LS.SUBTIPO, P.INDICADOR, LKC.TIPO_CLIENTE \n        FROM EFECTY_VOC.BT_COMENTARIOS C \n        JOIN EFECTY_VOC.BT_INTERACCIONES I ON C.INTERACCION_ID = I.INTERACCION_ID \n        LEFT JOIN EFECTY_VOC.LK_MEDIO_INGRESO M ON M.MEDIO_INGRESO_ID = I.MEDIO_INGRESO_ID \n        LEFT JOIN EFECTY_VOC.LK_PREGUNTA P ON P.PREGUNTA_ID = C.PREGUNTA_ID \n        LEFT JOIN EFECTY_VOC.LK_WRAPUP W ON W.WRAPUP_ID = C.WRAPUP_ID \n        LEFT JOIN EFECTY_VOC.LK_SUBTIPO LS ON LS.SUBTIPO_ID = C.SUBTIPO\n        LEFT JOIN EFECTY_VOC.LK_TIPO_CLIENTE LKC ON LKC.TIPO_CLIENTE_ID = I.TIPO_CLIENTE_ID\n        WHERE 1=1 \n        AND I.FECHA >= '{var_FechaDesde}' \n        AND I.FECHA < '{var_FechaHasta_Query}' \n        \"\"\"\n\n\nBT_COMENTARIOS = spark.read \\\n                      .format(\"jdbc\") \\\n                      .option(\"url\", synapse_url) \\\n                      .option(\"user\", synapse_user) \\\n                      .option(\"password\", synapse_password)\\\n                      .option(\"query\", query) \\\n                      .load() \\\n                      .toPandas()\n\n\nif len(BT_COMENTARIOS) <= 0:\n    dbutils.notebook.exit('No se encontaron datos') #Aca termina la corrida porque no hay datos\nelse:\n    print(f'Se recuperaron {len(BT_COMENTARIOS)} registros')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c9f310ec-5f75-4013-b0c8-cf3508d6bc1b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/utils.py:79: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [INTERACCION_ID, PREGUNTA_ID, TEMA_ID, WRAPUP_ID, VALOR, SUBTIPO_BT, SENTIMIENTO, CLASE_ID, MEDIO_INGRESO_ID, INDICADOR] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\nSe recuperaron 1050 registros\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/utils.py:79: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [INTERACCION_ID, PREGUNTA_ID, TEMA_ID, WRAPUP_ID, VALOR, SUBTIPO_BT, SENTIMIENTO, CLASE_ID, MEDIO_INGRESO_ID, INDICADOR] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\nSe recuperaron 1050 registros\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Analisis Dataset Recuperado"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"09b4065d-1949-467e-9e13-e296a179a7a1"}}},{"cell_type":"code","source":["# ANALISIS \nBT_COMENTARIOS[['INTERACCION_ID','MEDIO_INGRESO','CANAL']].groupby(['CANAL','MEDIO_INGRESO']).count().sort_values(by='CANAL')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"583f65e6-dada-464d-823b-57b5e8638dd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>INTERACCION_ID</th>\n    </tr>\n    <tr>\n      <th>CANAL</th>\n      <th>MEDIO_INGRESO</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CUSTOMER SERVICE</th>\n      <th>CHAT</th>\n      <td>9120</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ENCUESTA</th>\n      <th>CRM</th>\n      <td>4254</td>\n    </tr>\n    <tr>\n      <th>IVR</th>\n      <td>5214</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">PQRS</th>\n      <th>CALL CENTER</th>\n      <td>2318</td>\n    </tr>\n    <tr>\n      <th>CHAT</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>CORREO ELECTRONICO</th>\n      <td>7443</td>\n    </tr>\n    <tr>\n      <th>FACEBOOK</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>LLAMADA</th>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>PRESENCIAL</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>TWITTER</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>WEB</th>\n      <td>533</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">RRSS</th>\n      <th>COMENTARIO</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>DM</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>MENCION</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>MESSENGER</th>\n      <td>1223</td>\n    </tr>\n    <tr>\n      <th>MURO</th>\n      <td>274</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>INTERACCION_ID</th>\n    </tr>\n    <tr>\n      <th>CANAL</th>\n      <th>MEDIO_INGRESO</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CUSTOMER SERVICE</th>\n      <th>CHAT</th>\n      <td>9120</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ENCUESTA</th>\n      <th>CRM</th>\n      <td>4254</td>\n    </tr>\n    <tr>\n      <th>IVR</th>\n      <td>5214</td>\n    </tr>\n    <tr>\n      <th rowspan=\"8\" valign=\"top\">PQRS</th>\n      <th>CALL CENTER</th>\n      <td>2318</td>\n    </tr>\n    <tr>\n      <th>CHAT</th>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>CORREO ELECTRONICO</th>\n      <td>7443</td>\n    </tr>\n    <tr>\n      <th>FACEBOOK</th>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>LLAMADA</th>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>PRESENCIAL</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>TWITTER</th>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>WEB</th>\n      <td>533</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">RRSS</th>\n      <th>COMENTARIO</th>\n      <td>29</td>\n    </tr>\n    <tr>\n      <th>DM</th>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>MENCION</th>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>MESSENGER</th>\n      <td>1223</td>\n    </tr>\n    <tr>\n      <th>MURO</th>\n      <td>274</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#################################################### TRABAJO SOBRE EL TEXTO #######################\n# BT_COMENTARIOS=BT_inicial.copy()\nlistl=[]\nfor i in BT_COMENTARIOS.columns.tolist():\n    listl.append(i.lower())\ndict_lower=dict(zip(list(BT_COMENTARIOS.columns),listl))\nBT_COMENTARIOS=BT_COMENTARIOS.rename(columns=dict_lower)\n\n\nif len(BT_COMENTARIOS)==0:\n    print('No se encontraron datos que analizar')\n\n#El comentario tal cual lo descargo, quedará con la marca \"comentario inicial\"\nBT_COMENTARIOS['comentario_inicial']=BT_COMENTARIOS['comentario']\n\n#Lo paso a string y lo hago todo lower\nBT_COMENTARIOS['comentario']=BT_COMENTARIOS['comentario'].astype(str)\nindex_ini=list(BT_COMENTARIOS.index)\n\nBT_COMENTARIOS.loc[index_ini,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x:x.lower())\n\n#Modifico algunas cuestiones que afectan sobre todo a los PQRS: quito los /n, y los numeros a un mismo formato\nBT_COMENTARIOS.loc[index_ini,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r'[\\n]{1,4}',' ',x)) #Mas que nada para las PQRS que tienen muchas lineas vacias, donde hay mucho \\n textual\nBT_COMENTARIOS.loc[index_ini,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r\"\"\"[' ']{1,4}\"\"\",' ',x)) #CONTINUACIÓN DE LO DE ARRIBA\nBT_COMENTARIOS.loc[index_ini,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r\"\"\"[0-9]{1,10}\"\"\",'numero',x))\nBT_COMENTARIOS.loc[index_ini,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(' app|$app',' aplicación ',str(x)))\n\n#Limpio comentarios de RRSS y Customer Service\nindex_rrss=BT_COMENTARIOS[(BT_COMENTARIOS['canal']=='RRSS')|(BT_COMENTARIOS['canal']=='CUSTOMER SERVICE')].index\n\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.findall(\".liente:(.*)\\**\",x)if 'liente:' in x else x)\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r'\\?','zzz',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r'\\.','bbb',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(',','qwqz',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub('[\\W]',' ',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub('qwqz',',',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub('bbb','.',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub('zzz','?',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub(r'\\s\\s',' ',str(x)))\nBT_COMENTARIOS.loc[index_rrss,'comentario']=BT_COMENTARIOS['comentario'].apply(lambda x: re.sub('Imagen .*? [0-9-a-z]{10,30}','',str(x)))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3e33861d-261e-40d8-8460-3cef3b25bb5c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Definicion BETO"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4dd2fa56-df58-4941-abd0-43d15addf227"}}},{"cell_type":"code","source":["######################## DEFINICION DE BETO/NLP  #########################\n#cargo el tokenizador de beto\ntokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n\n#donde voy a trabajar\n# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice=\"cpu\"\n#Vuelvo a definir la estructura del modelo donde voy a trabajar ( es la misma que en el entrenamiento)\nclass BERTSentimentClassifier(nn.Module):\n    def __init__(self, n_classes):\n        super(BERTSentimentClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"pytorch/\")\n        self.drop = nn.Dropout(p=0.3)\n        self.linear = nn.Linear(self.bert.config.hidden_size, n_classes)\n\n    def forward(self, input_ids, attention_mask):\n        _, cls_output = self.bert(\n            input_ids = input_ids,\n            attention_mask = attention_mask,\n            return_dict=False\n        )\n        drop_output = self.drop(cls_output)\n        output = self.linear(drop_output)\n        return output\n\n#Defino el proceso del modelo para analizar el texto\ndef classifySentiment(review_text):\n    encoding_review = tokenizer.encode_plus(\n        review_text,\n        truncation = True,\n        add_special_tokens = True,\n        return_token_type_ids = False,\n        padding=True,\n    #       pad_to_max_length = True,\n        return_attention_mask = True,\n        return_tensors = 'pt'\n        )\n\n    input_ids = encoding_review['input_ids'].to(device)\n    attention_mask = encoding_review['attention_mask'].to(device)\n    output = model(input_ids, attention_mask)\n    _, prediction = torch.max(output, dim=1) #El output es un vector de NCLASSES dimensiones (3). Aca, se va a quedar con el valor mas alto, quien será el elegido \n    #   return prediction.tolist()[0],output.tolist()[0][0],output.tolist()[0][1],output.tolist()[0][2]\n    return prediction.tolist()[0]\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5106b3de-20d1-41a3-a1e6-3b8e48cda607"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Pregunta"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d3447fbc-fcda-40aa-a08b-84fe9adbe7c5"}}},{"cell_type":"code","source":["######################## GENERACIÓN DEL INDICADOR: EL IDENTIFICACIÓN DE PREGUNTA #########################\n#CLASIFICA EN NPS, SENTIMIENTO, ESFUERZO, NULL SATISFACCIÓN\n\n#Selecciono el segmento al que quiero que corra el modelo\nindex_indicador=BT_COMENTARIOS[BT_COMENTARIOS['canal']=='ENCUESTA'].index\n\n#Cargo el modelo\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/modelV1_preguntas_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n#Asi se entrenó a modelV1_preguntas_BETO_uncased_fine_tune. no se pueden modificar\n\n#Genero el diccionario\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_preg={0:'Null',1:'Satisfacción',2:'Esfuerzo',3:'NPS',4:'Sentimiento'}\nquery = \"SELECT INDICADOR_ID, INDICADOR FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_LK_INDICADOR\"\ndict_preg = spark.read \\\n                 .format(\"jdbc\") \\\n                 .option(\"url\", synapse_url) \\\n                 .option(\"user\", synapse_user) \\\n                 .option(\"password\", synapse_password)\\\n                 .option(\"query\", query) \\\n                 .load() \\\n                 .orderBy('INDICADOR_ID') \\\n                 .toPandas() \\\n                 .set_index('INDICADOR_ID') \\\n                 .T \\\n                 .to_dict('index')['INDICADOR']\n\n\nBT_COMENTARIOS['indicador_id']=-99\nBT_COMENTARIOS.loc[index_indicador,'indicador_id']=BT_COMENTARIOS.loc[index_indicador,'pregunta'].apply(lambda x:classifySentiment(x))\n\n\n\n#Genero la tabla diccionario\nschema = StructType([\n    StructField('INDICADOR_ID', IntegerType(), False),\n    StructField('INDICADOR', StringType(), False)\n])\n\nLK_INDICADOR = spark.createDataFrame(dict_preg.items(), schema) \nnombre_archivo = f'{path_contenedor_lk}/LK_INDICADOR'\nLK_INDICADOR.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d20fc603-50ac-4e26-b50b-3a9589ab4e77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Sentimiento"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef823145-27c5-4361-a851-d3c611408406"}}},{"cell_type":"code","source":["############################# GENERACIÓN DEL SENTIMIENTO ##############################################\n\n#Selecciono el segmento al que quiero que corra el modelo\nindex_sen=BT_COMENTARIOS[\n                ((BT_COMENTARIOS['canal']=='PQRS')&(\n                            (BT_COMENTARIOS['medio_ingreso']=='CORPORATIVO')|\n                            (BT_COMENTARIOS['medio_ingreso']=='WEB')|\n                            (BT_COMENTARIOS['medio_ingreso']=='CORREO ELECTRONICO')))|\n                ((BT_COMENTARIOS['canal']=='RRSS'))|\n                ((BT_COMENTARIOS['canal']=='ENCUESTA')&\n                            (BT_COMENTARIOS['medio_ingreso']=='CRM')&\n                            (BT_COMENTARIOS['indicador']==4))].index\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/BETO_sentimiento_V2.pkl', map_location=torch.device('cpu'))\n#modelV9_BETO_uncased_fine_tune modelo viejo 19.4.2022\n\nBT_COMENTARIOS.loc[index_sen,'sentimientoV4']=BT_COMENTARIOS.loc[index_sen,'comentario'].apply(lambda x:classifySentiment(x))\n\n#Cargo el modelo\n# https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n\n#Trabajo sobre los resultados\nBT_COMENTARIOS['sentimiento']=BT_COMENTARIOS['sentimientoV4'].apply(lambda x: 0.5 if x==1 else x)\nBT_COMENTARIOS['sentimiento']=BT_COMENTARIOS['sentimiento'].apply(lambda x: 1 if x==2 else x)\nBT_COMENTARIOS.drop(columns=['sentimientoV4'],inplace=True)\n\n#Modifico el formato\nBT_COMENTARIOS['sentimiento']=BT_COMENTARIOS['sentimiento'].apply(lambda x: -99 if pd.isna(x) else x)\nBT_COMENTARIOS['sentimiento']=BT_COMENTARIOS['sentimiento'].apply(lambda x: float(x))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00e0431d-5d89-4c6e-9263-b583b11a8679"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Temas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1ed1bb1f-f5d4-4a6c-8bfc-0c7672c1f7eb"}}},{"cell_type":"code","source":["##################### GENERACION DE TABLA TEMAS\n#Extracción del diccionario\n# 2022-04-01: Ultima version que deberia devolver el dataframe:\n# DicTemas = pd.read_excel('/dbfs/Efecty_VoC/BETOmodel/Diccionario temas.xlsx')\nquery = \"SELECT ORIGEN, [SUBTIPO/WRAPUP/ENCUESTA], [TEMÁTICA] FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_TEMAS\"\nDicTemas = spark.read \\\n                 .format(\"jdbc\") \\\n                 .option(\"url\", synapse_url) \\\n                 .option(\"user\", synapse_user) \\\n                 .option(\"password\", synapse_password)\\\n                 .option(\"query\", query) \\\n                 .load() \\\n                 .toPandas() \n\n\n#GENERO EL DIC DE TEMA Y TEMA_ID\n# 2022-04-01: Ultima version que deberia devolver el dataframe:\n# DicTemas2 = pd.read_excel('/dbfs/Efecty_VoC/BETOmodel/Diccionario temas.xlsx',sheet_name='Hoja2')\nquery = \"SELECT TEMA_ID, TEMA FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_LK_TEMA\"\nDicTemas2 = spark.read \\\n                 .format(\"jdbc\") \\\n                 .option(\"url\", synapse_url) \\\n                 .option(\"user\", synapse_user) \\\n                 .option(\"password\", synapse_password)\\\n                 .option(\"query\", query) \\\n                 .load() \\\n                 .orderBy('TEMA_ID') \\\n                 .toPandas() \n\ndic_tema_id=dict(list(zip(DicTemas2['TEMA'],DicTemas2['TEMA_ID'])))\n\nDicTemas['TEMA_ID']=DicTemas['TEMÁTICA'].apply(lambda x: int(dic_tema_id[x]))\nDic_Temas_subtipo=dict(list(zip(DicTemas['SUBTIPO/WRAPUP/ENCUESTA'][DicTemas['ORIGEN']=='Subtipo-PQRS'],\n                                DicTemas['TEMA_ID'][DicTemas['ORIGEN']=='Subtipo-PQRS'])))\nDic_Temas_wrapups=dict(list(zip(DicTemas['SUBTIPO/WRAPUP/ENCUESTA'][DicTemas['ORIGEN']=='wrapups'],\n                                DicTemas['TEMA_ID'][DicTemas['ORIGEN']=='wrapups'])))\nDic_Temas_enc=dict(list(zip(DicTemas['SUBTIPO/WRAPUP/ENCUESTA'][DicTemas['ORIGEN']=='Encuestas'],\n                            DicTemas['TEMA_ID'][DicTemas['ORIGEN']=='Encuestas'])))\n\n\nBT_COMENTARIOS.reset_index(inplace=True)\n\n\n#Paso a formato string las columnas donde voy a aplicar el diccionario\nBT_COMENTARIOS['subtipo']=BT_COMENTARIOS['subtipo'].astype(str)\nindex_st=BT_COMENTARIOS[BT_COMENTARIOS['subtipo']=='None'].index\nBT_COMENTARIOS.loc[index_st,'subtipo']=''\nBT_COMENTARIOS['wrapup']=BT_COMENTARIOS['wrapup'].astype(str)\nindex_wr=BT_COMENTARIOS[BT_COMENTARIOS['wrapup']=='None'].index\nBT_COMENTARIOS.loc[index_wr,'wrapup']=''\nBT_COMENTARIOS['encuesta']=BT_COMENTARIOS['encuesta'].astype(str)\nindex_enc=BT_COMENTARIOS[BT_COMENTARIOS['encuesta']=='None'].index\nBT_COMENTARIOS.loc[index_enc,'encuesta']=''\n\n#Los index! se aplicará tema a todo lo que tenga o: subtipo, wrapup o encuesta\n#Extracción de index para según origen\nindex_sub=BT_COMENTARIOS[BT_COMENTARIOS['subtipo']!=''].index\nindex_rrss=BT_COMENTARIOS[BT_COMENTARIOS['wrapup']!=''].index\nindex_enc=BT_COMENTARIOS[BT_COMENTARIOS['encuesta']!=''].index\n\n#Alpico los diccionarios según los index\nBT_COMENTARIOS.loc[index_enc,'tema_id']=BT_COMENTARIOS['encuesta'].apply(lambda x: Dic_Temas_enc.get(x) if  Dic_Temas_enc.get(x)!='' else x) \nBT_COMENTARIOS.loc[index_sub,'tema_id']=BT_COMENTARIOS['subtipo'].apply(lambda x: Dic_Temas_subtipo.get(x) if  Dic_Temas_subtipo.get(x)!='' else x) \nBT_COMENTARIOS.loc[index_rrss,'tema_id']=BT_COMENTARIOS['wrapup'].apply(lambda x: Dic_Temas_wrapups.get(x) if  Dic_Temas_wrapups.get(x)!='' else x) \n\n\n# Todo lo que tenga wrapup nulo y sea RRSS, debería tener temática Otros!!!\n\n####### a todas las encuestas con sentimiento(indicador_id=4), les correra este modelo. Si no es el valor espedaro, hardcodear \"Medición\" o que efecty genere otro dataset para esa encuesta puntual\nindex_tem=BT_COMENTARIOS[(BT_COMENTARIOS['encuesta']!='')&(BT_COMENTARIOS['indicador_id']==4)].index\n\n#Cargo el modelo\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/modelV_categv3_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\n#Asi se entrenó a modelV_categv3_BETO_uncased_fine_tune. no se pueden modificar\n\n#Diccionario viejo\ndic_PAPs={1:'Capacitación',2:'Convenios y franquicias',3:'Publicidad',\n        4:'Otros',5:'Satisfacción',6:'Sieweb Live',0:'Soporte a PAPs',7:'Sin comentarios',8: 'Recaudo'}\n\n#Diccionario nuevo, cuando metamos el nuevo modelo\n# dic_PAPs={1:'Capacitación',2:'convenios gral',3:'Otros',\n#         4:'Otros',5:'Otros',6:'Solicitud Sistema PAP',0:'PAPs',7:'Otros',8: 'Topes'}\n\n#A cada tema, le asigno el id universal de temas, proveniente de \"Diccionario temas.xlsx\"\nBT_COMENTARIOS.loc[index_tem,'tema_id']=BT_COMENTARIOS['comentario'].apply(lambda x:dic_tema_id[dic_PAPs[classifySentiment(x)]])\n\n#Modifico el formato\nBT_COMENTARIOS['tema_id']=BT_COMENTARIOS['tema_id'].apply(lambda x: -99 if pd.isna(x) else x)\nBT_COMENTARIOS['tema_id']=BT_COMENTARIOS['tema_id'].apply(lambda x: int(x))\n\n\n# ############# DESDE ACA, APLICO BETO_TEMAS PARA LOS NUEVOS TEMAS NO MAPEADOS INICIALMENTE\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/modelV_temasv5_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\n#Genero los index para identificar los subtipos/wrapups/encuestas no mapeadas inicialmente \nindex_tem_w=BT_COMENTARIOS[(BT_COMENTARIOS['encuesta']=='')&(BT_COMENTARIOS['subtipo']=='')&(BT_COMENTARIOS['tema_id']==-99)].index\n\nif list(index_tem_w)!=[]:\n    #Preparo el formato tal cual como se entreno\n    BT_COMENTARIOS['wrapup2']=BT_COMENTARIOS['wrapup']\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x: str(x).lower())\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub(' dev.','devolución',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('inf.|inf ','información',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('/|Corresponsal Bancario -|1-|1|cliente corporativo|cliente natural|cliente|corporativo|usuario final|colaborado de red|P_|Q_|In_|S_',' ',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('\\(|\\)|_|-',' ',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('tu cuenta','addidas',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('   ',' ',x))\n    BT_COMENTARIOS.loc[index_tem_w,'wrapup2']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x:   re.sub('  ',' ',x))\n    #Aplico beto_temas a los WEC no mapeados\n    BT_COMENTARIOS.loc[index_tem_w,'tema_id']=BT_COMENTARIOS.loc[index_tem_w,'wrapup2'].apply(lambda x: classifySentiment(x))\n\n\n# #REPITO PROCESO PARA SUBTIPO\nindex_tem_s=BT_COMENTARIOS[(BT_COMENTARIOS['wrapup']=='')&(BT_COMENTARIOS['encuesta']=='')&(BT_COMENTARIOS['tema_id']==-99)].index\nif list(index_tem_s)!=[]:\n    #Preparo el formato tal cual como se entreno\n    BT_COMENTARIOS['subtipo2']=BT_COMENTARIOS['subtipo']\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x: str(x).lower())\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub(' dev.','devolución',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('inf.|inf ','información',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('/|Corresponsal Bancario -|1-|1|cliente corporativo|cliente natural|cliente|corporativo|usuario final|colaborado de red|P_|Q_|In_|S_',' ',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('\\(|\\)|_|-',' ',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('tu cuenta','addidas',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('   ',' ',x))\n    BT_COMENTARIOS.loc[index_tem_s,'subtipo2']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x:   re.sub('  ',' ',x))\n    #Aplico beto_temas a los WEC no mapeados\n    BT_COMENTARIOS.loc[index_tem_s,'tema_id']=BT_COMENTARIOS.loc[index_tem_s,'subtipo2'].apply(lambda x: classifySentiment(x))\n\n\n#REPITO PROCESO PARA ENCUESTA\nindex_tem_e=BT_COMENTARIOS[(BT_COMENTARIOS['wrapup']=='')&(BT_COMENTARIOS['subtipo']=='')&(BT_COMENTARIOS['tema_id']==-99)].index\nif list(index_tem_s)!=[]:\n    #Preparo el formato tal cual como se entreno\n    BT_COMENTARIOS['encuesta2']=BT_COMENTARIOS['encuesta']\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x: str(x).lower())\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub(' dev.','devolución',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('inf.|inf ','información',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('/|Corresponsal Bancario -|1-|1|cliente corporativo|cliente natural|cliente|corporativo|usuario final|colaborado de red|P_|Q_|In_|S_',' ',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('\\(|\\)|_|-',' ',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('tu cuenta','addidas',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('   ',' ',x))\n    BT_COMENTARIOS.loc[index_tem_e,'encuesta2']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x:   re.sub('  ',' ',x))\n    #Aplico beto_temas a los WEC no mapeados\n    BT_COMENTARIOS.loc[index_tem_e,'tema_id']=BT_COMENTARIOS.loc[index_tem_e,'encuesta2'].apply(lambda x: classifySentiment(x))\n    \n\n#Genero la tabla diccionario\nschema = StructType([\n    StructField('TEMA_ID', IntegerType(), False),\n    StructField('TEMA', StringType(), False)\n])\n\ndic_tema_id_invertido = dict(list(zip(DicTemas2['TEMA_ID'],DicTemas2['TEMA'])))\nLK_TEMA = spark.createDataFrame(dic_tema_id_invertido.items(), schema) \nnombre_archivo = f'{path_contenedor_lk}/LK_TEMA'\nLK_TEMA.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3b23fbf4-0c5d-4c17-b99c-37247f7f7e9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">KeyError</span>                                  Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-855632569816487&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span> <span class=\"ansi-red-fg\">#A cada tema, le asigno el id universal de temas, proveniente de &#34;Diccionario temas.xlsx&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\"> </span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">.</span>loc<span class=\"ansi-blue-fg\">[</span>index_tem<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;tema_id&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">=</span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;comentario&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span>dic_tema_id<span class=\"ansi-blue-fg\">[</span>dic_PAPs<span class=\"ansi-blue-fg\">[</span>classifySentiment<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span> <span class=\"ansi-red-fg\">#Modifico el formato</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pandas/core/series.py</span> in <span class=\"ansi-cyan-fg\">apply</span><span class=\"ansi-blue-fg\">(self, func, convert_dtype, args, **kwds)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4136</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4137</span>                 values <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>object<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_values\n<span class=\"ansi-green-fg\">-&gt; 4138</span><span class=\"ansi-red-fg\">                 </span>mapped <span class=\"ansi-blue-fg\">=</span> lib<span class=\"ansi-blue-fg\">.</span>map_infer<span class=\"ansi-blue-fg\">(</span>values<span class=\"ansi-blue-fg\">,</span> f<span class=\"ansi-blue-fg\">,</span> convert<span class=\"ansi-blue-fg\">=</span>convert_dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4139</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   4140</span>         <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>mapped<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">and</span> isinstance<span class=\"ansi-blue-fg\">(</span>mapped<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> Series<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">pandas/_libs/lib.pyx</span> in <span class=\"ansi-cyan-fg\">pandas._libs.lib.map_infer</span><span class=\"ansi-blue-fg\">()</span>\n\n<span class=\"ansi-green-fg\">&lt;command-855632569816487&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;lambda&gt;</span><span class=\"ansi-blue-fg\">(x)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span> <span class=\"ansi-red-fg\">#A cada tema, le asigno el id universal de temas, proveniente de &#34;Diccionario temas.xlsx&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\"> </span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">.</span>loc<span class=\"ansi-blue-fg\">[</span>index_tem<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;tema_id&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">=</span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;comentario&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span>dic_tema_id<span class=\"ansi-blue-fg\">[</span>dic_PAPs<span class=\"ansi-blue-fg\">[</span>classifySentiment<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span> <span class=\"ansi-red-fg\">#Modifico el formato</span>\n\n<span class=\"ansi-red-fg\">KeyError</span>: &#39;Topes&#39;</div>","errorSummary":"<span class=\"ansi-red-fg\">KeyError</span>: &#39;Topes&#39;","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">KeyError</span>                                  Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-855632569816487&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span> <span class=\"ansi-red-fg\">#A cada tema, le asigno el id universal de temas, proveniente de &#34;Diccionario temas.xlsx&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\"> </span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">.</span>loc<span class=\"ansi-blue-fg\">[</span>index_tem<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;tema_id&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">=</span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;comentario&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span>dic_tema_id<span class=\"ansi-blue-fg\">[</span>dic_PAPs<span class=\"ansi-blue-fg\">[</span>classifySentiment<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span> <span class=\"ansi-red-fg\">#Modifico el formato</span>\n\n<span class=\"ansi-green-fg\">/databricks/python/lib/python3.8/site-packages/pandas/core/series.py</span> in <span class=\"ansi-cyan-fg\">apply</span><span class=\"ansi-blue-fg\">(self, func, convert_dtype, args, **kwds)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4136</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4137</span>                 values <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>astype<span class=\"ansi-blue-fg\">(</span>object<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>_values\n<span class=\"ansi-green-fg\">-&gt; 4138</span><span class=\"ansi-red-fg\">                 </span>mapped <span class=\"ansi-blue-fg\">=</span> lib<span class=\"ansi-blue-fg\">.</span>map_infer<span class=\"ansi-blue-fg\">(</span>values<span class=\"ansi-blue-fg\">,</span> f<span class=\"ansi-blue-fg\">,</span> convert<span class=\"ansi-blue-fg\">=</span>convert_dtype<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   4139</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   4140</span>         <span class=\"ansi-green-fg\">if</span> len<span class=\"ansi-blue-fg\">(</span>mapped<span class=\"ansi-blue-fg\">)</span> <span class=\"ansi-green-fg\">and</span> isinstance<span class=\"ansi-blue-fg\">(</span>mapped<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-cyan-fg\">0</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">,</span> Series<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">pandas/_libs/lib.pyx</span> in <span class=\"ansi-cyan-fg\">pandas._libs.lib.map_infer</span><span class=\"ansi-blue-fg\">()</span>\n\n<span class=\"ansi-green-fg\">&lt;command-855632569816487&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;lambda&gt;</span><span class=\"ansi-blue-fg\">(x)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     84</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     85</span> <span class=\"ansi-red-fg\">#A cada tema, le asigno el id universal de temas, proveniente de &#34;Diccionario temas.xlsx&#34;</span>\n<span class=\"ansi-green-fg\">---&gt; 86</span><span class=\"ansi-red-fg\"> </span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">.</span>loc<span class=\"ansi-blue-fg\">[</span>index_tem<span class=\"ansi-blue-fg\">,</span><span class=\"ansi-blue-fg\">&#39;tema_id&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">=</span>BT_COMENTARIOS<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;comentario&#39;</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">.</span>apply<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span>dic_tema_id<span class=\"ansi-blue-fg\">[</span>dic_PAPs<span class=\"ansi-blue-fg\">[</span>classifySentiment<span class=\"ansi-blue-fg\">(</span>x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">]</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     87</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">     88</span> <span class=\"ansi-red-fg\">#Modifico el formato</span>\n\n<span class=\"ansi-red-fg\">KeyError</span>: &#39;Topes&#39;</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Frases / Causa Raiz"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ab872e2-8449-4622-b7b2-ec6acfb3f345"}}},{"cell_type":"code","source":["############################# EXTRACCION DE FRASES/CAUSA RAIZ ######################################\n\n#Se entreno solo para encuestas CRM,indicador_id=4\n\nindex_CR=BT_COMENTARIOS[(BT_COMENTARIOS['canal']=='PQRS')|(BT_COMENTARIOS['canal']=='RRSS')|\n                ((~BT_COMENTARIOS['encuesta'].isna())&(BT_COMENTARIOS['indicador_id']==4)&(BT_COMENTARIOS['medio_ingreso']=='CRM'))].index\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/modelV_causaraizv1_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_causa_raiz={0:'Producto',    \n#         1:'Operativo',\n#         2:'Mantenimiento',\n#         3:'Trato con cliente',\n#         4:'Precio',\n#         5:'No Aplica'\n#         }\nquery = \"SELECT CAUSA_RAIZ_ID, CAUSA_RAIZ FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_LK_CAUSA_RAIZ\"\ndict_causa_raiz = spark.read \\\n                        .format(\"jdbc\") \\\n                        .option(\"url\", synapse_url) \\\n                        .option(\"user\", synapse_user) \\\n                        .option(\"password\", synapse_password)\\\n                        .option(\"query\", query) \\\n                        .load() \\\n                        .orderBy('CAUSA_RAIZ_ID') \\\n                        .toPandas() \\\n                        .set_index('CAUSA_RAIZ_ID') \\\n                        .T \\\n                        .to_dict('index')['CAUSA_RAIZ']\n\n\nBT_COMENTARIOS.loc[index_CR,'comentario_CR']=BT_COMENTARIOS.loc[index_CR,'comentario'].apply(lambda x:re.sub('[0-9]{1,20}','numero',x))\nBT_COMENTARIOS.loc[index_CR,'comentario_CR']=BT_COMENTARIOS.loc[index_CR,'comentario_CR'].apply(lambda x:re.sub('\\W',' ',x))\nBT_COMENTARIOS.loc[index_CR,'causa_raiz_id']=BT_COMENTARIOS.loc[index_CR,'comentario_CR'].apply(lambda x:classifySentiment(x))\n\n\n#Genero la tabla diccionario\nschema = StructType([\n    StructField('CAUSA_RAIZ_ID', IntegerType(), False),\n    StructField('CAUSA_RAIZ', StringType(), False)\n])\n\nLK_CAUSA_RAIZ = spark.createDataFrame(dict_causa_raiz.items(), schema) \nnombre_archivo = f'{path_contenedor_lk}/LK_CAUSA_RAIZ'\nLK_CAUSA_RAIZ.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f3cf38ff-9431-4264-b62b-58108a268a3c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Palabra"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"143ee35f-1985-4dc6-a049-c438d2b44279"}}},{"cell_type":"code","source":["############################# EXTRACCION DE PALABRA ######################################\n# descargar 'es_core_news_lg' (python -m spacy download es_core_news_lg)\n# subprocess.run(python -m spacy download es_core_news_lg)\n\nnlp = spacy.load('es_core_news_lg')\n\nBT_COMENTARIOS['palabra']=''\n\n\nindex_P=BT_COMENTARIOS[(BT_COMENTARIOS['medio_ingreso']!='LLAMADA')&(BT_COMENTARIOS['medio_ingreso']!='IVR')&((BT_COMENTARIOS['indicador_id']!=1)&(BT_COMENTARIOS['indicador_id']!=2)&(BT_COMENTARIOS['indicador_id']!=3))].index\n\n# for i in range(0,len(BT_COMENTARIOS['comentario'])):\nfor i in index_P:\n    try:\n        doc=nlp(BT_COMENTARIOS['comentario'][i])\n        g1=[]\n        for  token in doc:\n            if (token.pos_=='NOUN')&(token.text!='número'):\n                g1.append(token.text)\n        BT_COMENTARIOS['palabra'][i]=g1\n    except:\n        pass\n\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: ', '.join(x))\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: re.sub(\"gracias|efecty|favor|cliente|día|dias|usuario|referencia|correo|usuaria|dia|dias|buen|buenos|numero|número|saludos|saludo|señores|caso\",'',x))\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: re.sub(\"[0-9]{1,20}\",'',x))\n\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: re.sub(r'\\\\n',' ',x))\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: re.sub('\\W',' ',x))\nBT_COMENTARIOS['palabra']=BT_COMENTARIOS['palabra'].apply(lambda x: re.sub('  ',' ',x))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e251c898-d783-4243-8b41-07b0b701ef4d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">&lt;command-855632569816489&gt;:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  BT_COMENTARIOS[&#39;palabra&#39;][i]=g1\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;command-855632569816489&gt;:20: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  BT_COMENTARIOS[&#39;palabra&#39;][i]=g1\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Punto Interaccion"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1730a1c-7f9a-4d66-b54e-dca68d3da139"}}},{"cell_type":"code","source":["############################# EXTRACCION DE PUNTO INTERACCIÓN ######################################\n\n#Se entreno solo para encuestas CRM,indicador_id=4\n\nindex_PI_Encuesta=BT_COMENTARIOS[(((BT_COMENTARIOS['tipo_cliente']!='NO IDENTIFICADO')&(BT_COMENTARIOS['tipo_cliente']!='NATURAL'))&(BT_COMENTARIOS['tipo_cliente']!='USUARIO FINAL'))\n                                 &(((BT_COMENTARIOS['encuesta']!='')&(BT_COMENTARIOS['indicador_id']==4)&(BT_COMENTARIOS['medio_ingreso']!='IVR'))|(BT_COMENTARIOS['canal']=='PQRS')|(BT_COMENTARIOS['canal']=='RRSS')| (BT_COMENTARIOS['canal']=='CUSTOMER SERVICE'))].index\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/model_Punto_interaccionV1_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\n#diccionarios del modelo, inmodificables\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_PI_inverse={ 0:'Experiencia del Cliente',\n# 1:'Facilitador Comercial',\n# 2:'Facilitador de Canales',\n# 3:'Facilitador de Negocios',\n# 4:'Gestión Interna',\n# 5:'Mesa de servicio',\n# 6:'No mapeado',\n# 7:'Operaciones (Regional)',\n# 9:'PAP',\n# 10:'Portal',\n# 8:'Sistema (Sieweb live)',\n# 11:'Canal Virtual'} #Este 11 (canalvirtual) esta creado, super hardcodeado. cuando tengamos un modelo de este para usuario final, elimiarlo\n\nquery = \"SELECT PUNTO_INTERACCION_ID, PUNTO_INTERACCION, CN_UF, PREGUNTA FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_LK_PUNTO_INTERACCION\"\ndict_spark = spark.read \\\n                 .format(\"jdbc\") \\\n                 .option(\"url\", synapse_url) \\\n                 .option(\"user\", synapse_user) \\\n                 .option(\"password\", synapse_password)\\\n                 .option(\"query\", query) \\\n                 .load() \n\ndict_PI_inverse = dict_spark.select('PUNTO_INTERACCION_ID','PUNTO_INTERACCION').orderBy('PUNTO_INTERACCION_ID').toPandas().set_index('PUNTO_INTERACCION_ID').T.to_dict('index')['PUNTO_INTERACCION']\n\nBT_COMENTARIOS['punto_interaccion_id']=-99\nBT_COMENTARIOS.loc[index_PI_Encuesta,'punto_interaccion_id']=BT_COMENTARIOS.loc[index_PI_Encuesta,'comentario'].apply(lambda x:classifySentiment(x))\n\n\n############ DESDE ACA, CORRER UN MODELO PARA NATURAL Y USUARIO FINAL (cuando se haga, eliminar el 11 de arriba)\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/PI para cliente final e naturalV2.pkl', map_location=torch.device('cpu'))\n\nindex_PI_UFyCN=BT_COMENTARIOS[(((BT_COMENTARIOS['tipo_cliente']=='NO IDENTIFICADO')|(BT_COMENTARIOS['tipo_cliente']=='NATURAL'))|(BT_COMENTARIOS['tipo_cliente']=='USUARIO FINAL'))\n                                 &(((BT_COMENTARIOS['encuesta']!='')&(BT_COMENTARIOS['indicador_id']==4)&(BT_COMENTARIOS['medio_ingreso']!='IVR'))|(BT_COMENTARIOS['canal']=='PQRS')|(BT_COMENTARIOS['canal']=='RRSS')| (BT_COMENTARIOS['canal']=='CUSTOMER SERVICE'))].index\n\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_PI_CNyUF={0: 0,\n#  1: 11,\n#  2: 12,\n#  3: 6,\n#  4: 4,\n#  5: 9}\n\ndict_PI_CNyUF = dict_spark.filter('CN_UF IS NOT NULL').select('CN_UF','PUNTO_INTERACCION_ID').orderBy('CN_UF').toPandas().set_index('CN_UF').T.to_dict('index')['PUNTO_INTERACCION_ID']\n\nBT_COMENTARIOS.loc[index_PI_UFyCN,'punto_interaccion_id']=BT_COMENTARIOS.loc[index_PI_UFyCN,'comentario'].apply(lambda x:dict_PI_CNyUF.get(classifySentiment(x)))\n\n\n##### punto de interaccion a preguntas encuestas\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/model_Punto_interaccion_preguntas_v1_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_PI_preg__={0:11,\n#  1:12,\n#  2:0,\n#  3:1,\n#  4:2,\n#  5:3,\n#  6:4,\n#  7:5,\n#  8:6,\n#  9:7,\n#  10:9,\n#  11:10}\n\ndict_PI_preg__ = dict_spark.filter('PREGUNTA IS NOT NULL').select('PREGUNTA','PUNTO_INTERACCION_ID').orderBy('PREGUNTA').toPandas().set_index('PREGUNTA').T.to_dict('index')['PUNTO_INTERACCION_ID']\n\n\nindex_Preg_Encuesta=BT_COMENTARIOS[(BT_COMENTARIOS['canal']=='ENCUESTA')&(BT_COMENTARIOS['indicador_id']!=4)].index\n\nBT_COMENTARIOS.loc[index_Preg_Encuesta,'punto_interaccion_id']=BT_COMENTARIOS.loc[index_Preg_Encuesta,'pregunta'].apply(lambda x:dict_PI_preg__.get(classifySentiment(x)))\n\n#Genero la tabla diccionario\nschema = StructType([\n    StructField('PUNTO_INTERACCION_ID', IntegerType(), False),\n    StructField('PUNTO_INTERACCION', StringType(), False)\n])\n\nLK_PUNTO_INTERACCION = spark.createDataFrame(dict_PI_inverse.items(), schema) \nnombre_archivo = f'{path_contenedor_lk}/LK_PUNTO_INTERACCION'\nLK_PUNTO_INTERACCION.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0b46d0ac-87d4-426c-83cf-79f714e4aa99"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Customer Journey"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"05921691-271f-4be7-954d-3ca6a1dc2496"}}},{"cell_type":"code","source":["############################# EXTRACCION DE CUSTOMER JOURNEY - NO NATURAL/FINAL ######################################\n#Se entreno solo para encuestas CRM,indicador_id=4\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/model_CustomerJourneyV1_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\nBT_COMENTARIOS['cliente']=BT_COMENTARIOS['encuesta'].apply(lambda x: ''.join(re.findall('(.*) -',x)))\nBT_COMENTARIOS['punto_interaccion']=BT_COMENTARIOS['punto_interaccion_id'].apply(lambda x: dict_PI_inverse.get(x))\nBT_COMENTARIOS['encuesta3']=BT_COMENTARIOS['encuesta'].apply(lambda x: ''.join(re.findall('-(.*)',x)))\nBT_COMENTARIOS['encuesta3']=BT_COMENTARIOS['encuesta3'].apply(lambda x: re.sub('\\dM\\d\\d','satisfacción',x))\n\nBT_COMENTARIOS['COMENTARIO_CJ']='El '+BT_COMENTARIOS['cliente']+' hablando de '+BT_COMENTARIOS['punto_interaccion']+' dijo: '+BT_COMENTARIOS['comentario']\n\nBT_COMENTARIOS['customer_journey_id']=-99\n\nindex_CJ_g1=BT_COMENTARIOS[(\n    ((BT_COMENTARIOS['tipo_cliente']!='NATURAL')|(BT_COMENTARIOS['tipo_cliente']!='USUARIO FINAL'))& \n    (\n        ((~BT_COMENTARIOS['encuesta'].isna())&(BT_COMENTARIOS['indicador_id']==4)|(BT_COMENTARIOS['medio_ingreso']!='IVR'))|\n        (BT_COMENTARIOS['canal']=='PQRS')|\n        (BT_COMENTARIOS['canal']=='RRSS')|\n        (BT_COMENTARIOS['canal']=='CUSTOMER SERVICE')))&(~BT_COMENTARIOS['COMENTARIO_CJ'].isna())].index\n\n\nBT_COMENTARIOS.loc[index_CJ_g1,'customer_journey_id']=BT_COMENTARIOS.loc[index_CJ_g1,'COMENTARIO_CJ'].apply(lambda x:classifySentiment(x))\n\n\n########################## 21/3/2022 CJ COLAB Y CORPO ENCUESTAS\n##SOLO PARA ENCUESTAS\nBT_COMENTARIOS['COMENTARIO_CJ']='El '+BT_COMENTARIOS['cliente']+' en la encuesta '+BT_COMENTARIOS['encuesta3']+' le preguntaron, '+BT_COMENTARIOS['pregunta']+' hablando de '+BT_COMENTARIOS['punto_interaccion']+' dijo: '+BT_COMENTARIOS['comentario']\n\n\nindex_CJ_g1_En=BT_COMENTARIOS[(\n    ((BT_COMENTARIOS['tipo_cliente']!='NATURAL')|(BT_COMENTARIOS['tipo_cliente']!='USUARIO FINAL'))& \n        (BT_COMENTARIOS['indicador_id']==4)&(BT_COMENTARIOS['medio_ingreso']!='IVR')&(BT_COMENTARIOS['canal']=='ENCUESTA')&(~BT_COMENTARIOS['COMENTARIO_CJ'].isna()))].index\n\nBT_COMENTARIOS.loc[index_CJ_g1_En,'customer_journey_id']=BT_COMENTARIOS.loc[index_CJ_g1_En,'COMENTARIO_CJ'].apply(lambda x:classifySentiment(x))\n\n# Hardcodeado. sucede que no tenemos suficientes muestras para hacerlo correctamente. en el dataset que nos pasaron, todo lo que es 'Colaborador de la Red - 2M21' con 2 preguntas de mesa de servicio y auxilar, son de 'Soporte continuo' y hay respuestas de SI y NO en su mayoría.\nindex_1CJ=BT_COMENTARIOS[((BT_COMENTARIOS['comentario']=='SI')|(BT_COMENTARIOS['comentario']=='NO'))&(BT_COMENTARIOS['encuesta']=='Colaborador de la Red - 2M21')].index\nBT_COMENTARIOS.loc[index_1CJ,'customer_journey_id']=0"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0f3d7977-b29b-4111-81ab-a6c624fe39c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["############################# EXTRACCION DE CUSTOMER JOURNEY - CLIENTE NATURAL/FINAL/NO IDENTIFICADO ######################################\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/CJ para cliente final e naturalV6.pkl', map_location=torch.device('cpu'))\n\n\n#Los ids para los clientes naturales y usuario final. Los agregue a mano en la tabla LK_CUSTOMER_JOURNEY\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_CJ_preg={5: 'Alistamiento',\n#  51: 'Atención al Cliente',\n#  52: 'Compra',\n#  8: 'Desvinculación',\n#  1: 'Mantenimiento comercial de la cuenta',\n#  3: 'Mantenimiento del PAP',\n#  56: 'No Mapeado',\n#  9: 'Parametrización del proyecto',\n#  7: 'Percepción de Marca',\n#  59: 'Precompra',\n#  2: 'Previnculación',\n#  6: 'Salida a Producción',\n#  0: 'Servicio y soporte continuo',\n#  4: 'Vinculación'}\n\nquery = \"SELECT CUSTOMER_JOURNEY_ID, CUSTOMER_JOURNEY, CN_UF, PREGUNTA FROM EFECTY_VOC_MODEL_NLP_LANDING.PARAM_LK_CUSTOMER_JOURNEY\"\ndict_spark = spark.read \\\n                 .format(\"jdbc\") \\\n                 .option(\"url\", synapse_url) \\\n                 .option(\"user\", synapse_user) \\\n                 .option(\"password\", synapse_password)\\\n                 .option(\"query\", query) \\\n                 .load() \n\ndict_CJ_preg = dict_spark.select('CUSTOMER_JOURNEY_ID','CUSTOMER_JOURNEY').orderBy('CUSTOMER_JOURNEY_ID').toPandas().set_index('CUSTOMER_JOURNEY_ID').T.to_dict('index')['CUSTOMER_JOURNEY']\n\n\nindex_CJ_g2=BT_COMENTARIOS[(\n    ((BT_COMENTARIOS['tipo_cliente']=='NATURAL')|(BT_COMENTARIOS['tipo_cliente']=='USUARIO FINAL')|(BT_COMENTARIOS['tipo_cliente']=='NO IDENTIFICADO'))& \n    (\n        ((~BT_COMENTARIOS['encuesta'].isna())&(BT_COMENTARIOS['indicador_id']==4)|(BT_COMENTARIOS['medio_ingreso']!='IVR'))|\n        (BT_COMENTARIOS['canal']=='PQRS')|\n        (BT_COMENTARIOS['canal']=='RRSS')|\n        (BT_COMENTARIOS['canal']=='CUSTOMER SERVICE')))&(~BT_COMENTARIOS['COMENTARIO_CJ'].isna())].index\n\n\n\n#Modelo que corre para CF y CN (revisar, con maru para ampliar el margen)\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_CJ_CNyF={0:59,\n#  1:52,\n# 2:7,\n# 3:51,\n# 4:56}\n\ndict_CJ_CNyF = dict_spark.filter('CN_UF IS NOT NULL').select('CN_UF','CUSTOMER_JOURNEY_ID').orderBy('CN_UF').toPandas().set_index('CN_UF').T.to_dict('index')['CUSTOMER_JOURNEY_ID']\n\nBT_COMENTARIOS.loc[index_CJ_g2,'customer_journey_id']=BT_COMENTARIOS.loc[index_CJ_g2,'comentario'].apply(lambda x:dict_CJ_CNyF.get(classifySentiment(x)))\n\n\n####APLICO CJ A LAS PREGUNTAS DE LAS ENCUESTAS -- NATURAL Y NO NATURAL\n\nmodel = torch.load('/dbfs/Efecty_VoC/BETOmodel/model_CustomerJourney_preguntas_v1_BETO_uncased_fine_tune.pkl', map_location=torch.device('cpu'))\n\nindex_Preg_Encuesta=BT_COMENTARIOS[(BT_COMENTARIOS['canal']=='ENCUESTA')&(BT_COMENTARIOS['indicador_id']!=4)].index\n\n# 2022-04-01: Ultima version que deberia devolver el diccionario:\n# dict_CJ_preg__={0:5,\n#  1:51,\n#  2:52,\n#  3:8,\n#  4:1,\n#  5:3,\n#  6:56,\n#  7:9,\n#  8:7,\n#  9:59,\n#  10:2,\n#  11:6,\n#  12:0,\n#  13:4}\n\ndict_CJ_preg__ = dict_spark.filter('PREGUNTA IS NOT NULL').select('PREGUNTA','CUSTOMER_JOURNEY_ID').orderBy('PREGUNTA').toPandas().set_index('PREGUNTA').T.to_dict('index')['CUSTOMER_JOURNEY_ID']\n\nBT_COMENTARIOS.loc[index_Preg_Encuesta,'customer_journey_id']=BT_COMENTARIOS.loc[index_Preg_Encuesta,'pregunta'].apply(lambda x:dict_CJ_preg__.get(classifySentiment(x)))\n\n#Genero la tabla diccionario\nschema = StructType([\n    StructField('CUSTOMER_JOURNEY_ID', IntegerType(), False),\n    StructField('CUSTOMER_JOURNEY', StringType(), False)\n])\n\nLK_CUSTOMER_JOURNEY = spark.createDataFrame(dict_CJ_preg.items(), schema) \nnombre_archivo = f'{path_contenedor_lk}/LK_CUSTOMER_JOURNEY'\nLK_CUSTOMER_JOURNEY.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63baf116-a218-442b-b0c5-b48ea882e506"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Armado Tabla Final"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7a1a20f-32f0-42e3-ab86-813428cd6b72"}}},{"cell_type":"code","source":["######################## PREPROCESO DE TABLAS  #########################\n\nBT_COMENTARIOS['comentario']=BT_COMENTARIOS['comentario_inicial']\ndf_bt_comentarios=BT_COMENTARIOS.copy()\n\n# columnas de bt_comentarios\ndf_bt_comentarios=df_bt_comentarios[['id','interaccion_id','pregunta_id','comentario','wrapupnote','wrapup_id','valor','subtipo_bt','fecha_proceso','clase_id','dato_id','medio_ingreso_id','sentimiento','tema_id','indicador_id','causa_raiz_id','palabra','punto_interaccion_id','customer_journey_id']] \ndf_bt_comentarios=df_bt_comentarios.rename(columns={'subtipo_bt':'subtipo'})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ff6ed51-1acf-482e-8cf6-aafdc6db58ed"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Doy formato a las columnas\ndf_bt_comentarios['comentario'].fillna('',inplace=True)\ndf_bt_comentarios['comentario']=df_bt_comentarios['comentario'].astype(pd.StringDtype())\ndf_bt_comentarios['wrapupnote'].fillna('',inplace=True)\ndf_bt_comentarios['wrapupnote']=df_bt_comentarios['wrapupnote'].astype(pd.StringDtype())\ndf_bt_comentarios['palabra'].fillna('',inplace=True)\ndf_bt_comentarios['palabra']=df_bt_comentarios['palabra'].astype(pd.StringDtype())\ndf_bt_comentarios['dato_id'].fillna('',inplace=True)\ndf_bt_comentarios['dato_id']=df_bt_comentarios['dato_id'].astype(pd.StringDtype())\n\ndf_bt_comentarios['medio_ingreso_id'].fillna(0,inplace=True)\ndf_bt_comentarios['medio_ingreso_id']=df_bt_comentarios['medio_ingreso_id'].astype(int)\ndf_bt_comentarios['pregunta_id'].fillna(0,inplace=True)\ndf_bt_comentarios['pregunta_id']=df_bt_comentarios['pregunta_id'].astype(int)\ndf_bt_comentarios['wrapup_id'].fillna(0,inplace=True)\ndf_bt_comentarios['wrapup_id']=df_bt_comentarios['wrapup_id'].astype(int)\ndf_bt_comentarios['clase_id'].fillna(0,inplace=True)\ndf_bt_comentarios['clase_id']=df_bt_comentarios['clase_id'].astype(int)\ndf_bt_comentarios['valor'].fillna(0,inplace=True)\ndf_bt_comentarios['valor']=df_bt_comentarios['valor'].astype(int)\ndf_bt_comentarios['subtipo'].fillna(0,inplace=True)\ndf_bt_comentarios['subtipo']=df_bt_comentarios['subtipo'].astype(int)\n\ndf_bt_comentarios.fillna(-99,inplace=True)\ndf_bt_comentarios['sentimiento']=df_bt_comentarios['sentimiento'].astype(float)\ndf_bt_comentarios['interaccion_id']=df_bt_comentarios['interaccion_id'].astype(int)\ndf_bt_comentarios['indicador_id']=df_bt_comentarios['indicador_id'].astype(int)\ndf_bt_comentarios['tema_id']=df_bt_comentarios['tema_id'].astype(int)\ndf_bt_comentarios['interaccion_id']=df_bt_comentarios['interaccion_id'].astype(int)\ndf_bt_comentarios['punto_interaccion_id']=df_bt_comentarios['punto_interaccion_id'].astype(int)\ndf_bt_comentarios['customer_journey_id']=df_bt_comentarios['customer_journey_id'].astype(int)\n\n\n# df_bt_comentarios.replace(-99,np.NaN,inplace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"70891044-bd3a-42a9-b631-07f9e29aa8dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Paso a formato upper\nlistr=[]\nfor i in df_bt_comentarios.columns.tolist():\n    listr.append(i.upper())\ndict_upper=dict(zip(list(df_bt_comentarios.columns),listr))\ndf_bt_comentarios=df_bt_comentarios.rename(columns=dict_upper)\n\n\ndf_bt_comentarios=df_bt_comentarios[['MEDIO_INGRESO_ID','DATO_ID','ID', 'INTERACCION_ID', 'PREGUNTA_ID','TEMA_ID', 'COMENTARIO', 'WRAPUPNOTE',\n       'WRAPUP_ID', 'VALOR', 'SUBTIPO', 'SENTIMIENTO','FECHA_PROCESO', 'CLASE_ID','INDICADOR_ID', 'CAUSA_RAIZ_ID', \n        'PALABRA','PUNTO_INTERACCION_ID', 'CUSTOMER_JOURNEY_ID']]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2fe8afb-4d15-4ed2-9fd5-1f5698f4113d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#Generacion de Parquet"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b6a35d9b-3b65-4683-80ad-e74c72294a2a"}}},{"cell_type":"code","source":["nombre_archivo = f'{path_contenedor_bt}/Corrida-BT_COMENTARIOS_{var_FechaDesde}_{var_FechaHasta}'\npy_insert = spark.createDataFrame(df_bt_comentarios)\npy_insert.write.mode('overwrite').parquet(nombre_archivo)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"703a557c-86d5-4527-8e75-7583be0bebae"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:300: UserWarning: createDataFrame attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  Cannot specify a mask or a size when passing an object that is converted with the __arrow_array__ protocol.\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:300: UserWarning: createDataFrame attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  Cannot specify a mask or a size when passing an object that is converted with the __arrow_array__ protocol.\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Diario NLP","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{"param_FechaHasta":{"nuid":"fdd70173-ceb7-49ae-a849-2165a7fe3305","currentValue":"","widgetInfo":{"widgetType":"text","name":"param_FechaHasta","defaultValue":"","label":"Fecha Hasta","options":{"widgetType":"text","validationRegex":null}}},"param_FechaDesde":{"nuid":"a785c5f7-157d-4b42-b0fc-a55ebb979e36","currentValue":"","widgetInfo":{"widgetType":"text","name":"param_FechaDesde","defaultValue":"","label":"Fecha Desde","options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":2062501769275486}},"nbformat":4,"nbformat_minor":0}
